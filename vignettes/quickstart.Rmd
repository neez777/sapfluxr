---
title: "Quick Start Guide to sapfluxr"
author: "Grant Joyce"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start Guide to sapfluxr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

# Introduction

**sapfluxr** processes and analyses sap flow data from ICT SFM1x heat pulse velocity (HPV) sensors. This guide walks you through the complete workflow from raw data to visualised results.

## Installation

```{r eval=FALSE}
# Install from GitHub
devtools::install_github("neez777/sapfluxr")
```

```{r}
library(sapfluxr)
library(ggplot2)  # For plotting
```

# Basic Workflow

## 1. Import Data

sapfluxr automatically detects and imports multiple data formats from ICT sensors:

```{r eval=FALSE}
# Import raw heat pulse data
heat_pulse_data <- read_heat_pulse_data("path/to/your/data.txt")
```

The import function will:
- Auto-detect the file format (ICT current, legacy, or CSV)
- Parse temperature measurements from all four thermistors (do, di, uo, ui)
- Extract diagnostic information (battery voltage, temperature, etc.)
- Validate data quality (if `validate_data = TRUE`)

```{r include=FALSE}
# Create example data for this vignette
set.seed(42)
n_pulses <- 10

# Simulate realistic temperature data
measurements <- data.frame(
  pulse_id = rep(1:n_pulses, each = 150),
  datetime = rep(seq(as.POSIXct("2024-03-15 08:00:00"),
                     by = "30 min", length.out = n_pulses), each = 150)
)

# Add time within each pulse
measurements$datetime <- measurements$datetime + rep(0:149, times = n_pulses)

# Simulate temperature data with realistic heat pulse response
for (i in 1:n_pulses) {
  pulse_rows <- (i-1)*150 + 1:150
  time_sec <- 0:149

  # Pre-pulse baseline temperatures
  baseline_do <- 18.5 + rnorm(1, 0, 0.1)
  baseline_di <- 18.4 + rnorm(1, 0, 0.1)
  baseline_uo <- 18.6 + rnorm(1, 0, 0.1)
  baseline_ui <- 18.3 + rnorm(1, 0, 0.1)

  # Heat pulse response (rises after 30 sec, peaks around 60-80 sec, decays)
  heat_response <- ifelse(time_sec < 30, 0,
                          exp(-(time_sec - 60)^2 / 800) * runif(1, 0.8, 1.2))

  measurements$do[pulse_rows] <- baseline_do + heat_response * 1.2 + rnorm(150, 0, 0.02)
  measurements$di[pulse_rows] <- baseline_di + heat_response * 1.0 + rnorm(150, 0, 0.02)
  measurements$uo[pulse_rows] <- baseline_uo + heat_response * 0.8 + rnorm(150, 0, 0.01)
  measurements$ui[pulse_rows] <- baseline_ui + heat_response * 0.7 + rnorm(150, 0, 0.01)
}

# Create diagnostic data
diagnostics <- data.frame(
  pulse_id = 1:n_pulses,
  datetime = seq(as.POSIXct("2024-03-15 08:00:00"), by = "30 min", length.out = n_pulses),
  batt_volt = runif(n_pulses, 3.9, 4.1),
  batt_current = c(rnorm(n_pulses-1, 15, 2), rnorm(1, 180, 10)),  # One high heating pulse
  batt_temp = rnorm(n_pulses, 25, 2),
  external_volt = rnorm(n_pulses, 21, 1),
  external_current = c(rnorm(n_pulses-1, 18, 2), rnorm(1, 75, 5))
)

# Create heat_pulse_data object
heat_pulse_data <- list(
  measurements = measurements,
  diagnostics = diagnostics,
  metadata = list(
    file_path = "example_data.txt",
    file_name = "example_data.txt",
    format = "ict_current",
    import_time = Sys.time(),
    file_size = 125000,
    file_size_mb = 0.12,
    n_pulses = n_pulses,
    n_measurements = nrow(measurements),
    chunk_size = 100000,
    r_version = paste(R.version$major, R.version$minor, sep = "."),
    package_version = "0.2.0"
  )
)
class(heat_pulse_data) <- c("heat_pulse_data", "list")
```

### Inspect Imported Data

```{r}
# Summary of imported data
str(heat_pulse_data, max.level = 2)

# View first few temperature measurements
head(heat_pulse_data$measurements)

# View diagnostic information
head(heat_pulse_data$diagnostics)
```

### (Optional) Correct for Clock Drift

If you notice the device clock has drifted (common with long deployments), you can correct timestamps before processing:

```{r eval=FALSE}
# Example: Device was 5 minutes fast when retrieved on 2025-01-16 08:00:00
# The device displayed 2025-01-16 08:05:00 at that moment

# Fix clock drift - pass the entire heat_pulse_data object
heat_pulse_data <- fix_clock_drift(
  data = heat_pulse_data,
  observed_device_time = as.POSIXct("2025-01-16 08:05:00", tz = "UTC"),
  observed_actual_time = as.POSIXct("2025-01-16 08:00:00", tz = "UTC")
)

# This automatically corrects both measurements and diagnostics
# Original timestamps are preserved in 'device_datetime' column
# Corrected timestamps replace the 'datetime' column
```

**How it works:**
- Assumes the device clock was accurate at deployment (dataset start)
- Applies a linear correction based on a single calibration point
- Preserves original timestamps in a `device_datetime` column
- Stores correction metadata as attributes for traceability

See `?fix_clock_drift` for full details and advanced options.

## 2. Calculate Heat Pulse Velocity

Calculate sap velocity using one or more established methods:

```{r}
# Calculate using multiple methods
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  show_progress = FALSE
)

# View results
head(vh_results)
```

### Available Calculation Methods

| Method | Best For | Reference |
|--------|----------|-----------|
| **HRM** | Low flows, reverse flows | Burgess et al. (2001) |
| **MHR** | Moderate flows | Lopez et al. (2021) |
| **HRMXa/b** | Enhanced HRM accuracy | Burgess & Bleby (unpublished) |
| **Tmax_Coh** | High flows | Cohen et al. (1981) |
| **Tmax_Klu** | High flows (adjusted) | Kluitenberg & Ham (2004) |

<!-- sDMA NOTE REMOVED - functionality being re-implemented in later workflow stage -->
<!-- **Note:** DMA (Dual Method Approach) is applied as post-processing using `apply_sdma_processing()` - see section below. -->

### Understanding the Output

```{r}
# Results structure
colnames(vh_results)

# Quality flags
table(vh_results$quality_flag)

# Summary by method
aggregate(Vh_cm_hr ~ method, data = vh_results, FUN = function(x) {
  c(mean = mean(x, na.rm = TRUE),
    sd = sd(x, na.rm = TRUE),
    n = sum(!is.na(x)))
})
```

### Two-Tier Quality Flag System

sapfluxr uses a **two-tier quality flag system** to distinguish between different types of data issues:

**Tier 1 - Calculation Quality (CALC_ prefix):**
Set during `calc_heat_pulse_velocity()`, indicates issues with the calculation itself:

- `CALC_FAILED` - Calculation returned NA (e.g., Tmax couldn't find peak)
- `CALC_INFINITE` - Calculation returned Inf (division by zero, etc.)
- `CALC_EXTREME` - Result outside physically realistic range

**Tier 2 - Data Quality (DATA_ prefix):**
Set during `flag_vh_quality()`, indicates issues with time series patterns:

- `DATA_MISSING` - No pulse recorded at expected timestamp
- `DATA_ILLOGICAL` - Exceeds hard maximum or species-specific thresholds
- `DATA_OUTLIER` - Statistical outlier (rolling median or rate of change)
- `DATA_SUSPECT` - Negative flow or cross-sensor anomaly

**OK** - No issues detected in either tier

```{r}
# View only high-quality results
good_results <- vh_results[vh_results$quality_flag == "OK", ]
nrow(good_results)

# View problematic results
bad_results <- vh_results[vh_results$quality_flag != "OK", ]
table(bad_results$quality_flag, bad_results$method)
```

## 2a. Quality Control and Outlier Detection

After calculating velocities, apply comprehensive quality control to detect missing data, outliers, and suspicious patterns:

```{r eval=FALSE}
# Apply quality control with default settings
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",  # Optional: species-specific thresholds
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE,
  detect_rate_of_change = TRUE
)

# View flagged data
vh_flagged <- qc_results$vh_flagged
table(vh_flagged$quality_flag)

# View gap report (missing data periods)
print(qc_results$gap_report)

# View outlier summary
print(qc_results$outlier_summary)
```

**What `flag_vh_quality()` detects:**

1. **Missing Pulses** - Detects gaps in time series and optionally adds DATA_MISSING rows
2. **Illogical Values** - Flags velocities exceeding hard maximum (500 cm/hr) or species-specific thresholds
3. **Statistical Outliers** - Uses rolling median (default 11-point window) to detect spikes
4. **Excessive Rate of Change** - Flags jumps > 4 cm/hr between consecutive measurements
5. **Cross-Sensor Anomalies** - Compares sensors at same timestamp to detect sensor failures
6. **Negative Flows** - Flags as SUSPECT (may be real reverse flows or sensor issues)

**Customise detection sensitivity:**

```{r eval=FALSE}
# More sensitive outlier detection
qc_results <- flag_vh_quality(
  vh_results,
  rolling_window = 7,           # Wider window (15 points total)
  rolling_threshold = 2.5,      # More sensitive (default: 3 MAD)
  max_change_cm_hr = 3,         # Stricter rate of change (default: 4)
  max_gap_to_fill_hours = 12    # Don't fill gaps > 12 hours (default: 24)
)
```

**Why simple methods work:**
Sap flow data typically has regular measurement intervals and gradual changes. Rolling median and rate-of-change detection effectively catch sensor spikes and logging errors without needing complex seasonal decomposition.

**Handling large gaps:**
Gaps larger than `max_gap_to_fill_hours` are reported in `gap_report` but NOT filled with MISSING rows to avoid creating thousands of entries. Only small gaps are filled.

See `?flag_vh_quality` for full details.

## 2b. Zero-Flow Correction

### Why Zero-Flow Correction?

Heat pulse velocity sensors can experience **probe spacing errors** or **systematic offsets** due to:
- Slight misalignment during installation
- Tree swelling/shrinking with moisture changes
- Bark expansion after rain events
- Seasonal wood movement
- Electronic/thermal baseline drift

These errors cause **systematic bias** in velocity estimates. During periods of true zero flow (no transpiration), imperfect probes will still report non-zero velocities.

sapfluxr provides **two alternative approaches** for zero-flow correction:

### Approach 1: Simple Linear Offset Correction (Universal)

A **simple empirical correction** that subtracts the mean velocity observed during zero-flow periods:

```
Vh_corrected = Vh_raw - offset
```

**Use this when:**
- You have identified genuine zero-flow periods (nighttime, dormant season, etc.)
- You're using non-HRM methods (MHR, Tmax)
- Offset is large (>5 cm/hr) and Burgess validation fails
- You want a simple, method-agnostic correction

**Apply zero-flow offset:**

```{r eval=FALSE}
# Define zero-flow periods (e.g., nighttime with known zero flow)
zero_periods <- list(
  list(start = "2024-01-15 22:00:00", end = "2024-01-16 06:00:00"),
  list(start = "2024-01-16 22:00:00", end = "2024-01-17 06:00:00")
)

# Apply linear offset correction to all methods
vh_corrected <- apply_zero_flow_offset(
  vh_results,
  zero_periods = zero_periods,
  sensors = c("outer", "inner"),
  methods = NULL  # NULL applies to all methods
)

# Check results
attr(vh_corrected, "zero_flow_offset_results")
```

**Important:** This is purely empirical - it doesn't account for the physics of probe misalignment. For HRM/HRMX methods, consider Approach 2 (Burgess correction) below.

---

### Approach 2: Burgess Spacing Correction (HRM/HRMX Only)

**The Burgess et al. (2001) correction** is a physics-based approach that:
1. Calculates the apparent velocity when true flow is zero (the "zero offset")
2. Derives correction coefficients accounting for probe spacing errors
3. Applies a nonlinear correction validated for HRM

**Use this when:**
- You're using HRM, HRMXa, or HRMXb methods
- Offset is within validation range (≤ ±5 cm/hr)
- You want physically-grounded correction

**Only works for HRM/HRMX methods.** For other methods, use Approach 1 (linear offset).

sapfluxr provides three methods for Burgess correction, listed in order of preference:

| Method | When to Use | Advantages |
|--------|-------------|------------|
| **Heartwood Reference** | Inner sensor is in heartwood | Continuous correction, real-time drift tracking |
| **Changepoint Detection** | Long deployments, baseline shifts | Automatic, objective, handles drift |
| **Manual Specification** | Domain knowledge available | Full user control |

---

### Method 1: Heartwood Reference (Preferred)

**When the inner sensor is positioned in heartwood** (beyond the sapwood), it provides a continuous "true zero" reference. Since heartwood has no water transport, any velocity measured at the inner sensor represents probe misalignment.

**First, check if heartwood reference is available:**

```{r eval=FALSE}
# Check probe geometry vs sapwood depth
hw_check <- check_heartwood_reference_available(
  probe_config = list(length = 35, inner_sensor = 7.5),  # Standard ICT probe

  sapwood_depth = 2.0,        # cm - YOUR tree's sapwood depth

  bark_thickness = 0.3,       # cm - bark thickness (optional)
  field_of_influence = 1.0    # cm - heat pulse influence radius (default 10mm)
)

print(hw_check)
```
**Output shows:**
- Inner sensor depth from cambium
- Margin into heartwood (must be >= field_of_influence/2)
- Whether heartwood reference is **AVAILABLE** or **NOT AVAILABLE**

**If available, apply heartwood reference correction:**

```{r eval=FALSE}
# Apply continuous correction using inner sensor as zero reference
hw_correction <- apply_heartwood_reference_correction(
  vh_data = vh_results,
  method = "HRM",
  k_assumed = 0.0025
)

# Corrected data has new column: Vh_cm_hr_hrc (heartwood ref corrected)
vh_corrected <- hw_correction$vh_corrected

# Check offset statistics
print(hw_correction$offset_summary)
```

**Understanding the Output:**

The `offset_summary` provides diagnostic information:

| Metric | Good | Acceptable | Warning |
|--------|------|------------|---------|
| Mean offset | < 1 cm/hr | 1-3 cm/hr | > 3 cm/hr |
| SD offset | < 1 cm/hr | 1-2 cm/hr | > 2 cm/hr |

**Quality Interpretation:**
- `GOOD`: Probe well-aligned, stable offset
- `ACCEPTABLE`: Moderate misalignment, correction working
- `WARNING`: Significant misalignment - check probe installation
- `VARIABLE`: High offset variability - may indicate issues

**How It Works:**

For each measurement:
1. Inner sensor Vh = instantaneous zero offset
2. Look up Burgess coefficients (a, b) for that offset
3. Correct outer sensor: `Vh_corrected = a × Vh_outer + b`

**Advantages:**
- Continuous (per-measurement) correction
- Tracks real-time drift
- No need to identify changepoints
- Works even when baseline is unstable

**Requirements:**
- Inner sensor must be in heartwood (use `check_heartwood_reference_available()`)
- Both inner and outer sensor data required
- Works with HRM method (Burgess correction validated for HRM)

---

### Method 2: Automatic Changepoint Detection

**When heartwood reference is not available** (inner sensor in sapwood), use changepoint-based correction. This method:

1. **Detects baseline shifts** - Identifies when the zero offset changes
2. **Segments the time series** - Divides data into periods with consistent alignment
3. **Applies segment-specific corrections** - Each segment gets its own correction

```{r eval=FALSE}
# Step 1: Calculate daily minimum velocities (represents baseline)
daily_min <- calculate_daily_minima(
  vh_data = vh_results,
  sensor_position = "outer",
  method = "HRM"
)

# Step 2: Detect changepoints (baseline shifts)
cpt_result <- detect_changepoints(
  daily_min = daily_min,
  penalty = "MBIC",              # Options: "MBIC" (conservative), "BIC", "Manual"
  detection_type = "mean",
  min_segment_days = 7,
  merge_short_segments = TRUE
)

# View detected changepoints
print(cpt_result$changepoints)
print(cpt_result$segments)

# Step 3: Apply correction to BOTH sensors
correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_results,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  k_assumed = 0.0025
)

vh_corrected <- correction$vh_corrected
```

**Key Points:**
- Changepoints detected from **outer sensor only** (more reliable)
- Same segments applied to **both inner and outer** sensors
- Each sensor gets its **own baseline** within each segment

**Penalty Selection:**
- **MBIC** (recommended) - Most conservative, fewest changepoints
- **BIC** - Moderate, more changepoints than MBIC
- **Manual** (e.g., `penalty_value = 50`) - Full control over sensitivity

---

### Method 3: Manual Changepoint Specification

When you have domain knowledge about probe conditions (field notes, known disturbance events):

```{r eval=FALSE}
# Specify changepoints manually
correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_results,
  changepoints = c("2024-03-15", "2024-06-10"),  # Your known changepoints
  method = "HRM"
)

vh_corrected <- correction$vh_corrected
```

**With Baseline Overrides:**

If you have known zero offsets (e.g., from cut-stem experiments):

```{r eval=FALSE}
correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_results,
  changepoints = c("2024-03-15", "2024-06-10"),
  baseline_overrides_outer = list(
    "seg_1" = 0.8,   # Segment 1: known outer sensor offset
    "seg_2" = 1.2    # Segment 2: known offset
    # Segment 3 auto-detects
  ),
  baseline_overrides_inner = list(
    "seg_1" = 1.1    # Segment 1: known inner sensor offset
    # Segments 2 and 3 auto-detect
  ),
  method = "HRM"
)
```

---

### Junction Smoothing (Optional)

After segment-based corrections, smooth discontinuities at segment boundaries:

```{r eval=FALSE}
vh_smoothed <- smooth_segment_junctions(
  vh_data = vh_corrected,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  window_size = 3
)
```

**Note:** Junction smoothing only applies to changepoint methods, not heartwood reference.

---

### Diagnostic Plots

```{r eval=FALSE}
# For changepoint methods: visualise segments
plot_changepoints_interactive(
  daily_min = cpt_result$daily_min_with_segments,
  changepoints = cpt_result$changepoints,
  segments = extract_segment_baselines(cpt_result),
  show_baseline_values = TRUE
)

# Compare before/after correction
plot_spacing_correction_comparison(
  spacing_result = correction,
  sensor_position = "outer",
  show_difference = TRUE
)

# Burgess coefficient lookup curves
lookup <- calculate_burgess_coefficients()
plot_burgess_coefficients(
  lookup_table = lookup,
  zero_vh_observed = c(0.8, 1.2),
  labels = c("Segment 1", "Segment 2")
)
```

### Severity Assessment

| Zero Offset | Severity | Interpretation |
|-------------|----------|----------------|
| ≤ 1 cm/hr | None/Minor | Typical field installation |
| 1-3 cm/hr | Minor | Acceptable, correction reliable |
| 3-5 cm/hr | Moderate | Significant misalignment |
| 5-10 cm/hr | Severe | Major misalignment, elevated uncertainty |
| > 10 cm/hr | Critical | **Discard data, reinstall probes** |

### Best Practices

1. **Check heartwood reference first** - Use `check_heartwood_reference_available()` before choosing method
2. **Always correct BEFORE downstream analyses** (flux scaling, tree water use)
3. **For changepoint methods:** Plot daily minima to identify potential changepoints
4. **Validate with field notes** - Compare detected changepoints with observations
5. **Document your approach** - Record which method used and why

### Integration with Quality Control

Spacing correction should be applied **after** quality flagging:

```{r eval=FALSE}
# Recommended workflow:
# 1. Calculate velocities
vh_results <- calc_heat_pulse_velocity(heat_pulse_data, methods = "HRM")

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Spacing correction - choose method based on probe position
hw_check <- check_heartwood_reference_available(
  probe_config = my_probe_config,
  sapwood_depth = my_sapwood_depth
)

if (hw_check$available) {
  # Preferred: Heartwood reference
  correction <- apply_heartwood_reference_correction(vh_flagged, method = "HRM")
} else {
  # Alternative: Changepoint-based
  daily_min <- calculate_daily_minima(vh_flagged)
  cpt_result <- detect_changepoints(daily_min)
  correction <- apply_spacing_correction_both_sensors(
    vh_flagged,
    changepoints = cpt_result$changepoints
  )
}

vh_corrected <- correction$vh_corrected
```

See `?check_heartwood_reference_available`, `?apply_heartwood_reference_correction`, `?apply_spacing_correction_both_sensors`, `?detect_changepoints`, and `?calculate_daily_minima` for detailed documentation.

## 2c. Wound Correction

### Why Wound Correction is Needed

When probes are inserted into tree sapwood, they physically damage the tissue, creating "wound" tissue around each probe hole. This wound tissue:

- Has different thermal properties than healthy sapwood
- Creates a thermal barrier affecting heat pulse propagation
- Causes **systematic underestimation** of sap velocity (40-60% or more)
- Effect increases with wound diameter and flow rate

### The Correction Method

Wound correction uses linear coefficients from Burgess et al. (2001) lookup tables:

```
Vc = B × Vh
```

Where:
- `Vc` = Corrected velocity (cm/hr)
- `B` = Correction coefficient (typically 1.7-2.6, depending on wound diameter)
- `Vh` = Input velocity (spacing-corrected)

The correction coefficient `B` depends on:
1. **Wound diameter** - The drill bit size used for probe installation (typically 1.7-3.0 mm)
2. **Probe spacing** - 5mm (standard) or 6mm (legacy)

### Applying Wound Correction

```{r eval=FALSE}
# View available wound coefficients
list_wound_coefficients()

# Apply wound correction (will prompt for confirmation)
vh_wound_corrected <- apply_wound_correction(
  vh_data = vh_corrected,        # After spacing correction
  wound_diameter = 0.20,          # 2.0mm drill bit (in cm)
  probe_spacing = "5mm"           # Standard ICT probe spacing
)

# Check the correction factor applied
unique(vh_wound_corrected$wound_correction_factor)  # e.g., 1.9216
```

### Reading Wound Diameter from Configuration

Wound diameter can be stored in wood properties YAML files:

```{r eval=FALSE}
# If wound_diameter is in wood_properties YAML
vh_wound_corrected <- apply_wound_correction(
  vh_data = vh_corrected,
  wood_properties = "eucalyptus"  # Reads wound_diameter from YAML
)
```

The YAML file includes:
```yaml
probe_installation:
  wound_diameter: 0.20    # cm (2.0mm drill bit)
  probe_spacing: '5mm'    # standard
```

### Wound Correction Coefficients

Common wound diameters and their correction factors (5mm probe spacing):

| Drill Bit | Wound (cm) | B Coefficient | Correction |
|-----------|------------|---------------|------------|
| 1.7 mm | 0.17 | 1.73 | +73% |
| 2.0 mm | 0.20 | 1.92 | +92% |
| 2.5 mm | 0.25 | ~2.25 | +125% |
| 3.0 mm | 0.30 | 2.64 | +164% |

### Workflow Position and Column Structure

Wound correction should be applied **after** zero-flow correction (either linear offset OR Burgess spacing):

```{r eval=FALSE}
# OPTION A: Zero-flow offset → Wound correction
# ===============================================
# 1. Calculate velocities
vh_results <- calc_heat_pulse_velocity(heat_pulse_data)

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Zero-flow offset correction (universal, all methods)
vh_zf_corrected <- apply_zero_flow_offset(
  vh_flagged,
  zero_periods = my_zero_periods
)
# Creates: Vh_cm_hr_zf

# 4. Wound correction (applies to Vh_cm_hr_zf)
vh_final <- apply_wound_correction(
  vh_data = vh_zf_corrected,
  wound_diameter = 0.20
)
# Creates: Vh_cm_hr_zf_wc
# Updates: Vh_cm_hr -> points to Vh_cm_hr_zf_wc
```

```{r eval=FALSE}
# OPTION B: Burgess spacing correction → Wound correction
# ========================================================
# 1-2. Calculate velocities and quality control (same as above)

# 3. Burgess spacing correction (HRM only)
daily_min <- calculate_daily_minima(vh_flagged, method = "HRM")
cpt_result <- detect_changepoints(daily_min)
correction <- apply_spacing_correction_both_sensors(
  vh_flagged,
  changepoints = cpt_result$changepoints,
  method = "HRM"
)
vh_spacing_corrected <- correction$vh_corrected
# Creates: Vh_cm_hr_sc (HRM only)

# 4. Wound correction (applies to Vh_cm_hr_sc for HRM)
vh_final <- apply_wound_correction(
  vh_data = vh_spacing_corrected,
  wound_diameter = 0.20
)
# Creates: Vh_cm_hr_sc_wc (HRM only)
# Updates: Vh_cm_hr -> points to Vh_cm_hr_sc_wc
```

**Column naming:**
- `Vh_cm_hr_raw` - Original uncorrected values (always present)
- `Vh_cm_hr_zf` - Zero-flow offset corrected
- `Vh_cm_hr_sc` - Burgess spacing corrected (HRM only)
- `Vh_cm_hr_zf_wc` - Zero-flow + wound corrected
- `Vh_cm_hr_sc_wc` - Spacing + wound corrected (HRM only)
- `Vh_cm_hr` - "Current best" pointer (updated at each correction stage)

**Important:** Zero-flow offset and Burgess spacing correction are **mutually exclusive**. Choose one or the other based on your method and offset magnitude.

See `?apply_wound_correction` and `?list_wound_coefficients` for detailed documentation.

## 2d. Method Calibration (Aligning Secondary Methods to HRM)

### Why Method Calibration?

After spacing and wound correction, **HRM** provides the most reliable sap velocity estimates across all flow conditions because it has been validated with Burgess correction. However, other methods (MHR, Tmax, HRMXa, etc.) may provide useful information at higher flow rates.

**Method calibration** aligns secondary methods to the HRM scale using regression in overlapping flow regions. This allows you to:
1. Use HRM at low flows (most accurate)
2. Use calibrated secondary methods at higher flows (better sensitivity)
3. Maintain consistency across the full flow range

**Important:** Calibration should be performed **AFTER** spacing and wound correction, when HRM values are most reliable.

### Workflow 1: Automatic Threshold Optimization (Single Method)

Find the optimal threshold for calibrating one secondary method to HRM:

```{r eval=FALSE}
# Find optimal threshold for MHR calibration
calibration_mhr <- find_optimal_calibration_threshold(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_method = "MHR",
  sensor_position = "outer",
  threshold_start = 0,
  threshold_max = 20,
  threshold_step = 0.5,
  fit_type = "auto",        # "linear", "quadratic", or "auto"
  create_plots = TRUE,
  verbose = TRUE
)

# View optimal result
print(calibration_mhr$optimal_threshold)   # e.g., 2.5 cm/hr
print(calibration_mhr$optimal_r_squared)   # e.g., 0.985
print(calibration_mhr$optimal_fit_type)    # "linear" or "quadratic"
```

**How it works:**
- Tests multiple threshold values (0 to 20 cm/hr by default)
- For each threshold, performs regression using only HRM values above that threshold
- Selects threshold with highest R²
- Returns diagnostic plots showing R² vs threshold

### Workflow 2: Manual Threshold Override

If you disagree with the automatic threshold selection (e.g., you prefer a threshold with slightly lower R² but more data points):

```{r eval=FALSE}
# Use manual threshold instead of automatic optimization
calibration_mhr <- find_optimal_calibration_threshold(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_method = "MHR",
  sensor_position = "outer",
  manual_threshold = 3.0,   # Your chosen threshold
  create_plots = TRUE
)

# Result will use your threshold, skip optimization
```

### Workflow 3: Multi-Method Batch Calibration

Calibrate multiple secondary methods at once:

```{r eval=FALSE}
# Calibrate all secondary methods to HRM
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_methods = c("MHR", "Tmax_Klu", "HRMXa"),
  sensor_position = "outer",
  threshold_start = 0,
  threshold_max = 20,
  threshold_step = 0.5
)

# View results for each method
print(calibrations$MHR$optimal_threshold)
print(calibrations$Tmax_Klu$optimal_threshold)
print(calibrations$HRMXa$optimal_threshold)
```

**With Mixed Manual/Automatic Thresholds:**

```{r eval=FALSE}
# Override specific methods, auto-optimize others
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_methods = c("MHR", "Tmax_Klu", "HRMXa"),
  sensor_position = "outer",
  manual_thresholds = list(
    MHR = 2.5,          # Manual threshold for MHR
    # Tmax_Klu auto-optimizes
    HRMXa = 1.5         # Manual threshold for HRMXa
  )
)
```

### Workflow 4: Apply Calibration Transformation

Once calibrated, transform your secondary method data to the HRM scale:

```{r eval=FALSE}
# Single method transformation
vh_calibrated_mhr <- transform_secondary_method(
  vh_original = vh_corrected,
  calibration = calibration_mhr$optimal_calibration,
  method = "MHR"
)

# Multi-method transformation (applies all calibrations)
vh_calibrated_all <- transform_multiple_methods(
  vh_original = vh_corrected,
  calibrations = calibrations
)
```

### Workflow 5: Interactive Comparison Plots

Visualize calibration results with interactive date range and method selection:

```{r eval=FALSE}
# Plot calibration comparison (interactive prompts)
plot_calibration_comparison(
  vh_original = vh_corrected,
  vh_calibrated = vh_calibrated_all,
  calibration = calibrations  # Pass multi-method object
)

# You'll be prompted to:
# 1. Select which method to plot (if multiple available)
# 2. Enter start date for time window
# 3. Enter end date for time window

# Or specify directly (non-interactive)
plot_calibration_comparison(
  vh_original = vh_corrected,
  vh_calibrated = vh_calibrated_all,
  calibration = calibrations,
  method = "MHR",                    # Specific method
  start_date = "2024-03-01",
  end_date = "2024-03-31",
  aggregation = "daily"              # "none", "hourly", "daily"
)
```

### Understanding Calibration Results

```{r eval=FALSE}
# Inspect calibration details
cal <- calibration_mhr$optimal_calibration

cat("Fit type:", cal$fit_type, "\n")         # "linear" or "quadratic"
cat("Intercept:", cal$coefficients[1], "\n")
cat("Slope:", cal$coefficients[2], "\n")
if (cal$fit_type == "quadratic") {
  cat("Quadratic term:", cal$coefficients[3], "\n")
}
cat("R²:", cal$r_squared, "\n")
cat("RMSE:", cal$rmse, "cm/hr\n")
cat("Sample size:", cal$n_points, "\n")
```

### Best Practices

1. **Always calibrate AFTER spacing correction** - HRM must be corrected first
2. **Use outer sensor for calibration** - More reliable, less wounding damage
3. **Check R² values** - Aim for R² > 0.90 for reliable calibration
4. **Validate threshold selection** - Review R² vs threshold plots
5. **Consider sample size** - Very high thresholds may have too few points
6. **Test sensitivity** - Try different thresholds to assess robustness
7. **Document your choices** - Record which thresholds and why

### Integration with Complete Workflow

```{r eval=FALSE}
# Complete workflow order:
# 1. Calculate velocities (multiple methods)
vh_results <- calc_heat_pulse_velocity(heat_pulse_data, methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"))

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Spacing correction (HRM only, both sensors)
daily_min <- calculate_daily_minima(vh_flagged, sensor_position = "outer", method = "HRM")
cpt_result <- detect_changepoints(daily_min)
correction <- apply_spacing_correction_both_sensors(vh_flagged, cpt_result$changepoints, method = "HRM")
vh_corrected <- correction$vh_corrected

# 4. Junction smoothing (HRM only)
vh_smoothed <- smooth_segment_junctions(vh_corrected, cpt_result$changepoints, method = "HRM")

# 5. Method calibration (THIS STEP - secondary methods to corrected HRM)
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_smoothed,
  primary_method = "HRM",
  secondary_methods = c("MHR", "HRMXa", "Tmax_Klu"),
  sensor_position = "outer"
)

# 6. Apply calibrations
vh_final <- transform_multiple_methods(vh_smoothed, calibrations)

# Now vh_final contains:
# - HRM: spacing-corrected and junction-smoothed (reference method)
# - MHR, HRMXa, Tmax_Klu: calibrated to HRM scale
```

See `?find_optimal_calibration_threshold`, `?calibrate_multiple_methods`, `?transform_secondary_method`, and `?plot_calibration_comparison` for detailed documentation.

## 3. Visualise Results

### Time Series Plot

```{r fig.width=8, fig.height=5}
# Plot velocity time series
plot_vh_timeseries(
  vh_results,
  methods = c("HRM", "MHR", "HRMXa"),
  sensor_position = "outer"
)
```

### Heat Pulse Trace Plot

Visualise individual heat pulse responses and see exactly where each method calculated its result:

```{r fig.width=8, fig.height=6}
# Plot trace for a single pulse
plot_heat_pulse_trace(
  heat_pulse_data,
  vh_results,
  pulse_id = 5,
  show_methods = c("HRM", "HRMXa", "Tmax_Klu")
)
```

The shaded regions and markers show which time points each method used for its calculation:
- **HRM**: Grey shaded window showing averaging period
- **HRMXa**: Blue shaded window showing averaging period
- **HRMXb**: Green shaded window showing averaging period
- **MHR**: Orange shaded window showing time span from upstream to downstream peak, with orange points and lines marking both upstream and downstream peaks
- **Tmax methods**: Dark green vertical line and point marking time to maximum temperature

This is invaluable for:
- Understanding why methods give different results
- Diagnosing problematic pulses
- Validating calculation windows
- Visualizing the temporal dynamics of heat pulse transport

### Method Comparison

```{r fig.width=8, fig.height=6}
# Compare two methods across all pulses
plot_method_comparison(
  vh_results,
  method1 = "HRM",
  method2 = "MHR",
  sensor_position = "outer"
)
```


# Configurations

## Wood Properties

Wood properties affect thermal calculations. Use built-in configurations or create custom ones:

```{r eval=FALSE}
# Use built-in configurations
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus"  # or "pine", "generic_sw"
)

# Override specific properties
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus",
  wood_overrides = list(
    thermal_diffusivity = 0.0028,  # cm²/s
    dbh = 45.2,                    # cm
    sapwood_depth = 3.5            # cm
  )
)
```

### Create Custom Wood Properties

Create a YAML file with your species-specific properties:

```yaml
# wood_my_species.yaml
species:
  common_name: "My Species"
  scientific_name: "Genus species"

thermal_properties:
  thermal_diffusivity:
    value: 0.0025
    units: "cm²/s"
    source: "Measured from cores"

  thermal_conductivity:
    value: 0.0050
    units: "W/(m·K)"

  volumetric_heat_capacity:
    value: 2.0
    units: "MJ/(m³·K)"

physical_properties:
  wood_density:
    value: 550
    units: "kg/m³"

  moisture_content:
    value: 0.40
    units: "fraction"

tree_measurements:
  dbh:
    value: 35.0
    units: "cm"

  sapwood_depth:
    value: 2.8
    units: "cm"
```

Load your custom configuration:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "path/to/wood_my_species.yaml"
)
```

## Probe Configuration

Probe configurations define hardware specifications:

```{r eval=FALSE}
# Use default symmetric probe (ICT SFM1x standard)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "symmetrical"  # Default
)

# Use asymmetric probe (CHPM optimised)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "asymmetrical"
)
```

### Create Custom Probe Configuration

For custom probe geometries:

```yaml
# probe_custom.yaml
probe_type: "custom_probe"
description: "Custom probe geometry"

geometry:
  probe_spacing:
    value: 0.6
    units: "cm"

  probe_diameter:
    value: 1.5
    units: "mm"

  thermistor_positions:
    downstream_outer: 0.6   # cm from heater
    downstream_inner: 0.3
    upstream_outer: -0.6
    upstream_inner: -0.3

measurement:
  heat_pulse_duration:
    value: 2.0
    units: "seconds"
```

# Advanced Topics

## Custom Calculation Parameters

Override default calculation windows:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = "HRM",
  parameters = list(
    pre_pulse = 30,      # Baseline period (sec)
    HRM_start = 70,      # HRM window start (sec)
    HRM_end = 110,       # HRM window end (sec)
    L = 0.5,             # HRMX lower bound (proportion of max temp)
    H = 0.8              # HRMX upper bound
  )
)
```

## Filter by Quality

The two-tier quality flag system (CALC_ and DATA_ prefixes) helps identify different types of issues:

```{r}
# Keep only high-quality results (no calculation or data issues)
good_results <- vh_results[vh_results$quality_flag == "OK", ]

# View all quality flags
table(vh_results$quality_flag, vh_results$method)

# Filter out calculation failures but keep data quality issues for manual review
calc_ok <- vh_results[!grepl("^CALC_", vh_results$quality_flag), ]

# After running flag_vh_quality(), you can filter by both tiers
# qc_results <- flag_vh_quality(vh_results)
# clean_data <- qc_results$vh_flagged[qc_results$vh_flagged$quality_flag == "OK", ]
```

## Export Results

```{r eval=FALSE}
# Export to CSV
write.csv(vh_results, "sap_velocity_results.csv", row.names = FALSE)

# Export with metadata
saveRDS(list(
  results = vh_results,
  metadata = heat_pulse_data$metadata,
  processing_date = Sys.time()
), "sap_velocity_complete.rds")
```

# Workflow Summary

```r
# Complete workflow with all processing steps
library(sapfluxr)

# PHASE 1: Import and Initial Calculations
# ========================================

# 1. Import
heat_pulse_data <- read_heat_pulse_data("mydata.txt")

# 1a. (Optional) Fix clock drift if detected
# heat_pulse_data <- fix_clock_drift(
#   data = heat_pulse_data,
#   observed_device_time = as.POSIXct("2025-01-16 08:05:00"),
#   observed_actual_time = as.POSIXct("2025-01-16 08:00:00")
# )

# 2. Calculate velocities (all methods)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  wood_properties = "eucalyptus"
)

# 2a. Apply quality control
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE
)
vh_flagged <- qc_results$vh_flagged

# PHASE 2: Zero-Flow Correction (Choose ONE approach)
# ====================================================

# OPTION A: Simple linear offset (universal, all methods)
# --------------------------------------------------------
zero_periods <- list(
  list(start = "2024-03-15 22:00:00", end = "2024-03-16 06:00:00"),
  list(start = "2024-03-16 22:00:00", end = "2024-03-17 06:00:00")
)

vh_zf_corrected <- apply_zero_flow_offset(
  vh_flagged,
  zero_periods = zero_periods
)
# Creates: Vh_cm_hr_zf for all methods

# OPTION B: Burgess spacing correction (HRM only)
# ------------------------------------------------
# Only if using HRM and offset ≤ ±5 cm/hr
daily_min <- calculate_daily_minima(
  vh_data = vh_flagged,
  sensor_position = "outer",
  method = "HRM"
)

cpt_result <- detect_changepoints(
  daily_min = daily_min,
  penalty = "MBIC",
  min_segment_days = 7
)

correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_flagged,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  k_assumed = 0.0025
)

vh_spacing_corrected <- correction$vh_corrected
# Creates: Vh_cm_hr_sc for HRM only

# Optional: Junction smoothing (HRM + changepoint methods only)
vh_smoothed <- smooth_segment_junctions(
  vh_data = vh_spacing_corrected,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  window_size = 3
)

# PHASE 3: Wound Correction
# ==========================

# Apply wound correction (works with either zero-flow approach)
vh_wound_corrected <- apply_wound_correction(
  vh_data = vh_zf_corrected,  # OR vh_spacing_corrected (if using Option B)
  wound_diameter = 0.20
)
# Creates: Vh_cm_hr_zf_wc (if from Option A)
#      or: Vh_cm_hr_sc_wc (if from Option B)
# Updates: Vh_cm_hr -> current best

# PHASE 4: Method Calibration (Optional)
# =======================================

# Calibrate secondary methods to corrected HRM
# Only if you have multiple methods and want consistency
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_wound_corrected,
  primary_method = "HRM",
  secondary_methods = c("MHR", "HRMXa", "Tmax_Klu"),
  sensor_position = "outer"
)

# Apply calibrations
vh_final <- transform_multiple_methods(
  vh_original = vh_wound_corrected,
  calibrations = calibrations
)

# PHASE 6: Visualisation and Export
# ==================================

# 3. Visualise results
plot_vh_timeseries(vh_final, methods = c("HRM", "MHR", "HRMXa"))
plot_calibration_comparison(vh_smoothed, vh_final, calibrations)

# 4. Export final processed data
write.csv(vh_final, "sap_velocity_final.csv", row.names = FALSE)

# Export with full metadata
saveRDS(list(
  data = vh_final,
  changepoints = cpt_result,
  correction = correction,
  calibrations = calibrations,
  processing_date = Sys.time()
), "sap_velocity_complete.rds")
```

## Common Workflows

### Standard Analysis
```r
# Use proven methods for routine analysis
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR")
)
```

### Method Comparison
```r
# Compare multiple methods to find the best for your data
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu")
)
```


# Getting Help

- **Package documentation**: `?calc_heat_pulse_velocity`
- **Report issues**: https://github.com/neez777/sapfluxr/issues
- **Method details**: See `knowledge_docs/` in package installation

# References

- Burgess, S. S. O., Adams, M. A., Turner, N. C., Beverly, C. R., Ong, C. K., Khan, A. A. H., & Bleby, T. M. (2001). An improved heat pulse method to measure low and reverse rates of sap flow in woody plants. *Tree Physiology*, 21(9), 589-598.

- Cohen, Y., Fuchs, M., & Green, G. C. (1981). Improvement of the heat pulse method for determining sap flow in trees. *Plant, Cell & Environment*, 4(5), 391-397.

- Forster, M. A. (2020). How significant is nocturnal sap flow? *Tree Physiology*, 40(8), 1179-1190.

- Kluitenberg, G. J., & Ham, J. M. (2004). Improved theory for calculating sap flow with the heat pulse method. *Agricultural and Forest Meteorology*, 126(1-2), 169-173.

- Lopez, J. G., Morán-López, T., Benito Garzón, M., & Oliveras Menor, I. (2021). An improved heat pulse method using a single probe for determining sap flow in temperate trees. *Tree Physiology*, 41(12), 2437-2449.
