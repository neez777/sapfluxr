---
title: "Quick Start Guide to sapfluxr"
author: "Grant Joyce"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start Guide to sapfluxr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

# Introduction

**sapfluxr** processes and analyses sap flow data from ICT SFM1x heat pulse velocity (HPV) sensors. This guide walks you through the complete workflow from raw data to visualised results.

## Installation

```{r eval=FALSE}
# Install from GitHub
devtools::install_github("neez777/sapfluxr")
```

```{r}
library(sapfluxr)
library(ggplot2)  # For plotting
```

# Basic Workflow

## 1. Import Data

sapfluxr automatically detects and imports multiple data formats from ICT sensors:

```{r eval=FALSE}
# Import raw heat pulse data
heat_pulse_data <- read_heat_pulse_data("path/to/your/data.txt")
```

The import function will:
- Auto-detect the file format (ICT current, legacy, or CSV)
- Parse temperature measurements from all four thermistors (do, di, uo, ui)
- Extract diagnostic information (battery voltage, temperature, etc.)
- Validate data quality (if `validate_data = TRUE`)

```{r include=FALSE}
# Create example data for this vignette
set.seed(42)
n_pulses <- 10

# Simulate realistic temperature data
measurements <- data.frame(
  pulse_id = rep(1:n_pulses, each = 150),
  datetime = rep(seq(as.POSIXct("2024-03-15 08:00:00"),
                     by = "30 min", length.out = n_pulses), each = 150)
)

# Add time within each pulse
measurements$datetime <- measurements$datetime + rep(0:149, times = n_pulses)

# Simulate temperature data with realistic heat pulse response
for (i in 1:n_pulses) {
  pulse_rows <- (i-1)*150 + 1:150
  time_sec <- 0:149

  # Pre-pulse baseline temperatures
  baseline_do <- 18.5 + rnorm(1, 0, 0.1)
  baseline_di <- 18.4 + rnorm(1, 0, 0.1)
  baseline_uo <- 18.6 + rnorm(1, 0, 0.1)
  baseline_ui <- 18.3 + rnorm(1, 0, 0.1)

  # Heat pulse response (rises after 30 sec, peaks around 60-80 sec, decays)
  heat_response <- ifelse(time_sec < 30, 0,
                          exp(-(time_sec - 60)^2 / 800) * runif(1, 0.8, 1.2))

  measurements$do[pulse_rows] <- baseline_do + heat_response * 1.2 + rnorm(150, 0, 0.02)
  measurements$di[pulse_rows] <- baseline_di + heat_response * 1.0 + rnorm(150, 0, 0.02)
  measurements$uo[pulse_rows] <- baseline_uo + heat_response * 0.8 + rnorm(150, 0, 0.01)
  measurements$ui[pulse_rows] <- baseline_ui + heat_response * 0.7 + rnorm(150, 0, 0.01)
}

# Create diagnostic data
diagnostics <- data.frame(
  pulse_id = 1:n_pulses,
  datetime = seq(as.POSIXct("2024-03-15 08:00:00"), by = "30 min", length.out = n_pulses),
  batt_volt = runif(n_pulses, 3.9, 4.1),
  batt_current = c(rnorm(n_pulses-1, 15, 2), rnorm(1, 180, 10)),  # One high heating pulse
  batt_temp = rnorm(n_pulses, 25, 2),
  external_volt = rnorm(n_pulses, 21, 1),
  external_current = c(rnorm(n_pulses-1, 18, 2), rnorm(1, 75, 5))
)

# Create heat_pulse_data object
heat_pulse_data <- list(
  measurements = measurements,
  diagnostics = diagnostics,
  metadata = list(
    file_path = "example_data.txt",
    file_name = "example_data.txt",
    format = "ict_current",
    import_time = Sys.time(),
    file_size = 125000,
    file_size_mb = 0.12,
    n_pulses = n_pulses,
    n_measurements = nrow(measurements),
    chunk_size = 100000,
    r_version = paste(R.version$major, R.version$minor, sep = "."),
    package_version = "0.2.0"
  )
)
class(heat_pulse_data) <- c("heat_pulse_data", "list")
```

### Inspect Imported Data

```{r}
# Summary of imported data
str(heat_pulse_data, max.level = 2)

# View first few temperature measurements
head(heat_pulse_data$measurements)

# View diagnostic information
head(heat_pulse_data$diagnostics)
```

### (Optional) Correct for Clock Drift

If you notice the device clock has drifted (common with long deployments), you can correct timestamps before processing:

```{r eval=FALSE}
# Example: Device was 5 minutes fast when retrieved on 2025-01-16 08:00:00
# The device displayed 2025-01-16 08:05:00 at that moment

# Fix clock drift - pass the entire heat_pulse_data object
heat_pulse_data <- fix_clock_drift(
  data = heat_pulse_data,
  observed_device_time = as.POSIXct("2025-01-16 08:05:00", tz = "UTC"),
  observed_actual_time = as.POSIXct("2025-01-16 08:00:00", tz = "UTC")
)

# This automatically corrects both measurements and diagnostics
# Original timestamps are preserved in 'device_datetime' column
# Corrected timestamps replace the 'datetime' column
```

**How it works:**
- Assumes the device clock was accurate at deployment (dataset start)
- Applies a linear correction based on a single calibration point
- Preserves original timestamps in a `device_datetime` column
- Stores correction metadata as attributes for traceability

See `?fix_clock_drift` for full details and advanced options.

## 2. Calculate Heat Pulse Velocity

Calculate sap velocity using one or more established methods:

```{r}
# Calculate using multiple methods
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  show_progress = FALSE
)

# View results
head(vh_results)
```

### Available Calculation Methods

| Method | Best For | Reference |
|--------|----------|-----------|
| **HRM** | Low flows, reverse flows | Burgess et al. (2001) |
| **MHR** | Moderate flows | Lopez et al. (2021) |
| **HRMXa/b** | Enhanced HRM accuracy | Burgess & Bleby (unpublished) |
| **Tmax_Coh** | High flows | Cohen et al. (1981) |
| **Tmax_Klu** | High flows (adjusted) | Kluitenberg & Ham (2004) |

<!-- sDMA NOTE REMOVED - functionality being re-implemented in later workflow stage -->
<!-- **Note:** DMA (Dual Method Approach) is applied as post-processing using `apply_sdma_processing()` - see section below. -->

### Understanding the Output

```{r}
# Results structure
colnames(vh_results)

# Quality flags
table(vh_results$quality_flag)

# Summary by method
aggregate(Vh_cm_hr ~ method, data = vh_results, FUN = function(x) {
  c(mean = mean(x, na.rm = TRUE),
    sd = sd(x, na.rm = TRUE),
    n = sum(!is.na(x)))
})
```

### Two-Tier Quality Flag System

sapfluxr uses a **two-tier quality flag system** to distinguish between different types of data issues:

**Tier 1 - Calculation Quality (CALC_ prefix):**
Set during `calc_heat_pulse_velocity()`, indicates issues with the calculation itself:

- `CALC_FAILED` - Calculation returned NA (e.g., Tmax couldn't find peak)
- `CALC_INFINITE` - Calculation returned Inf (division by zero, etc.)
- `CALC_EXTREME` - Result outside physically realistic range

**Tier 2 - Data Quality (DATA_ prefix):**
Set during `flag_vh_quality()`, indicates issues with time series patterns:

- `DATA_MISSING` - No pulse recorded at expected timestamp
- `DATA_ILLOGICAL` - Exceeds hard maximum or species-specific thresholds
- `DATA_OUTLIER` - Statistical outlier (rolling median or rate of change)
- `DATA_SUSPECT` - Negative flow or cross-sensor anomaly

**OK** - No issues detected in either tier

```{r}
# View only high-quality results
good_results <- vh_results[vh_results$quality_flag == "OK", ]
nrow(good_results)

# View problematic results
bad_results <- vh_results[vh_results$quality_flag != "OK", ]
table(bad_results$quality_flag, bad_results$method)
```

## 2a. Quality Control and Outlier Detection

After calculating velocities, apply comprehensive quality control to detect missing data, outliers, and suspicious patterns:

```{r eval=FALSE}
# Apply quality control with default settings
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",  # Optional: species-specific thresholds
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE,
  detect_rate_of_change = TRUE
)

# View flagged data
vh_flagged <- qc_results$vh_flagged
table(vh_flagged$quality_flag)

# View gap report (missing data periods)
print(qc_results$gap_report)

# View outlier summary
print(qc_results$outlier_summary)
```

**What `flag_vh_quality()` detects:**

1. **Missing Pulses** - Detects gaps in time series and optionally adds DATA_MISSING rows
2. **Illogical Values** - Flags velocities exceeding hard maximum (500 cm/hr) or species-specific thresholds
3. **Statistical Outliers** - Uses rolling median (default 11-point window) to detect spikes
4. **Excessive Rate of Change** - Flags jumps > 4 cm/hr between consecutive measurements
5. **Cross-Sensor Anomalies** - Compares sensors at same timestamp to detect sensor failures
6. **Negative Flows** - Flags as SUSPECT (may be real reverse flows or sensor issues)

**Customise detection sensitivity:**

```{r eval=FALSE}
# More sensitive outlier detection
qc_results <- flag_vh_quality(
  vh_results,
  rolling_window = 7,           # Wider window (15 points total)
  rolling_threshold = 2.5,      # More sensitive (default: 3 MAD)
  max_change_cm_hr = 3,         # Stricter rate of change (default: 4)
  max_gap_to_fill_hours = 12    # Don't fill gaps > 12 hours (default: 24)
)
```

**Why simple methods work:**
Sap flow data typically has regular measurement intervals and gradual changes. Rolling median and rate-of-change detection effectively catch sensor spikes and logging errors without needing complex seasonal decomposition.

**Handling large gaps:**
Gaps larger than `max_gap_to_fill_hours` are reported in `gap_report` but NOT filled with MISSING rows to avoid creating thousands of entries. Only small gaps are filled.

See `?flag_vh_quality` for full details.

## 2b. Zero-Flow Correction (Spacing Adjustment)

### Why Zero-Flow Correction?

Heat pulse velocity sensors can experience **probe spacing errors** due to:
- Slight misalignment during installation
- Tree swelling/shrinking with moisture changes
- Bark expansion after rain events
- Seasonal wood movement

These spacing errors cause **systematic bias** in velocity estimates. During periods of true zero flow (no transpiration), misaligned probes will still report non-zero velocities.

**The Burgess et al. (2001) correction** uses zero-flow calibration to:
1. Calculate the apparent velocity when true flow is zero (the "zero offset")
2. Derive correction coefficients that account for probe misalignment
3. Apply a linear correction to all velocity measurements

### The Changepoint Approach

For datasets spanning days to months, probe alignment often **changes over time** due to tree swelling/shrinking, seasonal wood movement, or environmental conditions. The changepoint-based correction method handles this by:

1. **Detecting baseline shifts** - Identifies when the zero offset changes
2. **Segmenting the time series** - Divides data into periods with consistent probe alignment
3. **Applying segment-specific corrections** - Each segment gets its own zero offset and correction coefficients

This matches the real-world workflow used by researchers analyzing long-term sap flow data.

### Workflow 1: Automatic Changepoint Detection

Let the algorithm detect changepoints and baseline shifts automatically:

```{r eval=FALSE}
# Step 1: Calculate daily minimum velocities
daily_min <- calculate_daily_minima(
  vh_data = vh_results,
  sensor_position = "outer",
  method = "HRM"
)

# Step 2: Detect changepoints (baseline shifts indicating probe movement)
cpt_result <- detect_changepoints(
  daily_min = daily_min,
  penalty = "MBIC",                  # Options: "MBIC" (conservative), "BIC", "Manual"
  detection_type = "mean",           # Detect mean changes (baseline shifts)
  min_segment_days = 7,              # Minimum segment length
  merge_short_segments = TRUE        # Merge spurious short segments
)

# View detected changepoints
print(cpt_result$changepoints)
print(cpt_result$segments)

# Step 3: Apply correction per segment (auto-detects baseline in each segment)
correction <- apply_spacing_correction_per_segment(
  vh_data = vh_results,
  changepoints = cpt_result$changepoints,
  sensor_position = "outer",
  method = "HRM",
  k_assumed = 0.0025
)

vh_corrected <- correction$vh_corrected
```

**When to Use Automatic Detection:**
- Long deployments (> 1 month)
- Data spans wet/dry seasonal transitions
- You want an objective, reproducible approach
- Unsure where baseline shifts occurred

**Penalty Selection:**
- **MBIC** (recommended) - Most conservative, fewest changepoints
- **BIC** - Moderate, more changepoints than MBIC
- **Manual** (e.g., `penalty_value = 50`) - Full control over sensitivity

### Workflow 2: Manual Changepoint Specification

When you have domain knowledge about probe conditions (e.g., you know when rain events occurred, when you repositioned probes), specify changepoints manually:

```{r eval=FALSE}
# Specify changepoints based on your knowledge
# Example: Rain event on March 15, probe adjustment on June 10
correction <- apply_manual_spacing_correction(
  vh_data = vh_results,
  manual_changepoints = c("2024-03-15", "2024-06-10"),
  sensor_position = "outer",
  method = "HRM"
)

vh_corrected <- correction$vh_corrected
```

**With Optional Baseline Overrides:**

If you know the zero offset values for specific periods (e.g., from cut-stem experiments or extended zero-flow periods):

```{r eval=FALSE}
correction <- apply_manual_spacing_correction(
  vh_data = vh_results,
  manual_changepoints = c("2024-03-15", "2024-06-10"),
  baseline_overrides = list(
    "2024-01-01/2024-03-15" = 0.8,  # Segment 1: user-specified
    # Segment 2 auto-detects (not specified)
    "2024-06-11/2024-12-31" = 1.5   # Segment 3: user-specified
  ),
  sensor_position = "outer"
)
```

**When to Use Manual Specification:**
- You have field notes about probe conditions
- Known disturbance events (rain, repositioning, animal damage)
- Cut-stem calibration data available
- Want to test sensitivity to specific changepoints

### Diagnostic Plots

Visualise changepoints and correction impacts:

```{r eval=FALSE}
# Interactive changepoint visualisation
plot_changepoints_interactive(
  daily_min = cpt_result$daily_min_with_segments,
  changepoints = cpt_result$changepoints,
  segments = extract_segment_baselines(cpt_result),
  show_baseline_values = TRUE
)

# Compare before/after correction
plot_spacing_correction_comparison(
  spacing_result = correction,
  sensor_position = "outer",
  show_difference = TRUE
)

# View Burgess coefficient lookup curves
lookup <- calculate_burgess_coefficients()
plot_burgess_coefficients(
  lookup_table = lookup,
  zero_vh_observed = c(0.8, 1.2),  # Your observed zero offsets
  labels = c("Segment 1", "Segment 2")
)
```

### Understanding Correction Results

```{r eval=FALSE}
# View segment-specific corrections
for (seg in correction$segment_results) {
  cat("\nSegment", seg$segment_id, ":\n")
  cat("  Period:", format(seg$start_datetime), "to", format(seg$end_datetime), "\n")
  cat("  Zero offset:", seg$zero_vh, "cm/hr\n")
  cat("  Baseline source:", seg$baseline_source, "\n")  # "auto-detected" or "user-specified"
  cat("  Correction:", seg$correction_formula, "\n")
  cat("  Severity:", seg$severity, "\n")
}

# Compare uncorrected vs corrected
summary(vh_results$Vh_cm_hr[vh_results$sensor_position == "outer"])
summary(vh_corrected$Vh_cm_hr_sc[vh_corrected$sensor_position == "outer"])
```

**Severity Assessment:**

| Zero Offset | Severity | Interpretation |
|-------------|----------|----------------|
| ≤ 1 cm/hr | None/Minor | Typical field installation |
| 1-3 cm/hr | Minor | Acceptable, correction reliable |
| 3-5 cm/hr | Moderate | Significant misalignment |
| 5-10 cm/hr | Severe | Major misalignment, elevated uncertainty |
| > 10 cm/hr | Critical | **Discard data, reinstall probes** |

### Best Practices

1. **Always correct BEFORE downstream analyses** (flux scaling, tree water use)
2. **Check for baseline shifts** - Plot daily minima to identify potential changepoints
3. **Use multiple segments for long deployments** - Don't assume constant alignment
4. **Validate with field notes** - Compare detected changepoints with field observations
5. **Correct both sensors independently** - They may have different offsets
6. **Document your approach** - Record whether automatic or manual, and why
7. **Create diagnostic plots** - Visually confirm segment quality

### Integration with Quality Control

Spacing correction should be applied **after** quality flagging:

```{r eval=FALSE}
# Recommended workflow order:
# 1. Calculate velocities
vh_results <- calc_heat_pulse_velocity(heat_pulse_data, methods = "HRM")

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Spacing correction (THIS STEP)
daily_min <- calculate_daily_minima(vh_flagged)
cpt_result <- detect_changepoints(daily_min)
correction <- apply_spacing_correction_per_segment(
  vh_data = vh_flagged,
  changepoints = cpt_result$changepoints,
  sensor_position = "outer"
)
vh_corrected <- correction$vh_corrected
```

See `?apply_spacing_correction_per_segment`, `?apply_manual_spacing_correction`, `?detect_changepoints`, and `?calculate_daily_minima` for detailed parameter documentation.
## 3. Visualise Results

### Time Series Plot

```{r fig.width=8, fig.height=5}
# Plot velocity time series
plot_vh_timeseries(
  vh_results,
  methods = c("HRM", "MHR", "HRMXa"),
  sensor_position = "outer"
)
```

### Heat Pulse Trace Plot

Visualise individual heat pulse responses and see exactly where each method calculated its result:

```{r fig.width=8, fig.height=6}
# Plot trace for a single pulse
plot_heat_pulse_trace(
  heat_pulse_data,
  vh_results,
  pulse_id = 5,
  show_methods = c("HRM", "HRMXa", "Tmax_Klu")
)
```

The shaded regions and markers show which time points each method used for its calculation:
- **HRM**: Grey shaded window showing averaging period
- **HRMXa**: Blue shaded window showing averaging period
- **HRMXb**: Green shaded window showing averaging period
- **MHR**: Orange shaded window showing time span from upstream to downstream peak, with orange points and lines marking both upstream and downstream peaks
- **Tmax methods**: Dark green vertical line and point marking time to maximum temperature

This is invaluable for:
- Understanding why methods give different results
- Diagnosing problematic pulses
- Validating calculation windows
- Visualizing the temporal dynamics of heat pulse transport

### Method Comparison

```{r fig.width=8, fig.height=6}
# Compare two methods across all pulses
plot_method_comparison(
  vh_results,
  method1 = "HRM",
  method2 = "MHR",
  sensor_position = "outer"
)
```


# Configurations

## Wood Properties

Wood properties affect thermal calculations. Use built-in configurations or create custom ones:

```{r eval=FALSE}
# Use built-in configurations
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus"  # or "pine", "generic_sw"
)

# Override specific properties
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus",
  wood_overrides = list(
    thermal_diffusivity = 0.0028,  # cm²/s
    dbh = 45.2,                    # cm
    sapwood_depth = 3.5            # cm
  )
)
```

### Create Custom Wood Properties

Create a YAML file with your species-specific properties:

```yaml
# wood_my_species.yaml
species:
  common_name: "My Species"
  scientific_name: "Genus species"

thermal_properties:
  thermal_diffusivity:
    value: 0.0025
    units: "cm²/s"
    source: "Measured from cores"

  thermal_conductivity:
    value: 0.0050
    units: "W/(m·K)"

  volumetric_heat_capacity:
    value: 2.0
    units: "MJ/(m³·K)"

physical_properties:
  wood_density:
    value: 550
    units: "kg/m³"

  moisture_content:
    value: 0.40
    units: "fraction"

tree_measurements:
  dbh:
    value: 35.0
    units: "cm"

  sapwood_depth:
    value: 2.8
    units: "cm"
```

Load your custom configuration:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "path/to/wood_my_species.yaml"
)
```

## Probe Configuration

Probe configurations define hardware specifications:

```{r eval=FALSE}
# Use default symmetric probe (ICT SFM1x standard)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "symmetrical"  # Default
)

# Use asymmetric probe (CHPM optimised)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "asymmetrical"
)
```

### Create Custom Probe Configuration

For custom probe geometries:

```yaml
# probe_custom.yaml
probe_type: "custom_probe"
description: "Custom probe geometry"

geometry:
  probe_spacing:
    value: 0.6
    units: "cm"

  probe_diameter:
    value: 1.5
    units: "mm"

  thermistor_positions:
    downstream_outer: 0.6   # cm from heater
    downstream_inner: 0.3
    upstream_outer: -0.6
    upstream_inner: -0.3

measurement:
  heat_pulse_duration:
    value: 2.0
    units: "seconds"
```

# Advanced Topics

## Custom Calculation Parameters

Override default calculation windows:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = "HRM",
  parameters = list(
    pre_pulse = 30,      # Baseline period (sec)
    HRM_start = 70,      # HRM window start (sec)
    HRM_end = 110,       # HRM window end (sec)
    L = 0.5,             # HRMX lower bound (proportion of max temp)
    H = 0.8              # HRMX upper bound
  )
)
```

## Filter by Quality

The two-tier quality flag system (CALC_ and DATA_ prefixes) helps identify different types of issues:

```{r}
# Keep only high-quality results (no calculation or data issues)
good_results <- vh_results[vh_results$quality_flag == "OK", ]

# View all quality flags
table(vh_results$quality_flag, vh_results$method)

# Filter out calculation failures but keep data quality issues for manual review
calc_ok <- vh_results[!grepl("^CALC_", vh_results$quality_flag), ]

# After running flag_vh_quality(), you can filter by both tiers
# qc_results <- flag_vh_quality(vh_results)
# clean_data <- qc_results$vh_flagged[qc_results$vh_flagged$quality_flag == "OK", ]
```

## Export Results

```{r eval=FALSE}
# Export to CSV
write.csv(vh_results, "sap_velocity_results.csv", row.names = FALSE)

# Export with metadata
saveRDS(list(
  results = vh_results,
  metadata = heat_pulse_data$metadata,
  processing_date = Sys.time()
), "sap_velocity_complete.rds")
```

# Workflow Summary

```r
# Complete workflow with all quality control steps
library(sapfluxr)

# 1. Import
heat_pulse_data <- read_heat_pulse_data("mydata.txt")

# 1a. (Optional) Fix clock drift if detected
# heat_pulse_data <- fix_clock_drift(
#   data = heat_pulse_data,
#   observed_device_time = as.POSIXct("2025-01-16 08:05:00"),
#   observed_actual_time = as.POSIXct("2025-01-16 08:00:00")
# )

# 2. Calculate velocities
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  wood_properties = "eucalyptus"
)

# 2a. Apply quality control
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE
)
vh_flagged <- qc_results$vh_flagged


# 3. Visualise
plot_vh_timeseries(vh_flagged, methods = c("HRM", "MHR", "HRMXa"))
plot_heat_pulse_trace(heat_pulse_data, vh_flagged, pulse_id = 1)

# 4. Export (only OK quality data)
clean_data <- vh_flagged[vh_flagged$quality_flag == "OK", ]
write.csv(clean_data, "sap_velocity_clean.csv", row.names = FALSE)
```

## Common Workflows

### Standard Analysis
```r
# Use proven methods for routine analysis
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR")
)
```

### Method Comparison
```r
# Compare multiple methods to find the best for your data
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu")
)
```


# Getting Help

- **Package documentation**: `?calc_heat_pulse_velocity`
- **Report issues**: https://github.com/neez777/sapfluxr/issues
- **Method details**: See `knowledge_docs/` in package installation

# References

- Burgess, S. S. O., Adams, M. A., Turner, N. C., Beverly, C. R., Ong, C. K., Khan, A. A. H., & Bleby, T. M. (2001). An improved heat pulse method to measure low and reverse rates of sap flow in woody plants. *Tree Physiology*, 21(9), 589-598.

- Cohen, Y., Fuchs, M., & Green, G. C. (1981). Improvement of the heat pulse method for determining sap flow in trees. *Plant, Cell & Environment*, 4(5), 391-397.

- Forster, M. A. (2020). How significant is nocturnal sap flow? *Tree Physiology*, 40(8), 1179-1190.

- Kluitenberg, G. J., & Ham, J. M. (2004). Improved theory for calculating sap flow with the heat pulse method. *Agricultural and Forest Meteorology*, 126(1-2), 169-173.

- Lopez, J. G., Morán-López, T., Benito Garzón, M., & Oliveras Menor, I. (2021). An improved heat pulse method using a single probe for determining sap flow in temperate trees. *Tree Physiology*, 41(12), 2437-2449.
