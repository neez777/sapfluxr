---
title: "Quick Start Guide to sapfluxr"
author: "Grant Joyce"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start Guide to sapfluxr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

# Introduction

**sapfluxr** processes and analyses sap flow data from ICT SFM1x heat pulse velocity (HPV) sensors. This guide walks you through the complete workflow from raw data to visualised results.

## Installation

```{r eval=FALSE}
# Install from GitHub
devtools::install_github("neez777/sapfluxr")
```

```{r}
library(sapfluxr)
library(ggplot2)  # For plotting
```

# Basic Workflow

## 1. Import Data

sapfluxr automatically detects and imports multiple data formats from ICT sensors:

```{r eval=FALSE}
# Import raw heat pulse data
heat_pulse_data <- read_heat_pulse_data("path/to/your/data.txt")
```

The import function will:
- Auto-detect the file format (ICT current, legacy, or CSV)
- Parse temperature measurements from all four thermistors (do, di, uo, ui)
- Extract diagnostic information (battery voltage, temperature, etc.)
- Validate data quality (if `validate_data = TRUE`)

```{r include=FALSE}
# Create example data for this vignette
set.seed(42)
n_pulses <- 10

# Simulate realistic temperature data
measurements <- data.frame(
  pulse_id = rep(1:n_pulses, each = 150),
  datetime = rep(seq(as.POSIXct("2024-03-15 08:00:00"),
                     by = "30 min", length.out = n_pulses), each = 150)
)

# Add time within each pulse
measurements$datetime <- measurements$datetime + rep(0:149, times = n_pulses)

# Simulate temperature data with realistic heat pulse response
for (i in 1:n_pulses) {
  pulse_rows <- (i-1)*150 + 1:150
  time_sec <- 0:149

  # Pre-pulse baseline temperatures
  baseline_do <- 18.5 + rnorm(1, 0, 0.1)
  baseline_di <- 18.4 + rnorm(1, 0, 0.1)
  baseline_uo <- 18.6 + rnorm(1, 0, 0.1)
  baseline_ui <- 18.3 + rnorm(1, 0, 0.1)

  # Heat pulse response (rises after 30 sec, peaks around 60-80 sec, decays)
  heat_response <- ifelse(time_sec < 30, 0,
                          exp(-(time_sec - 60)^2 / 800) * runif(1, 0.8, 1.2))

  measurements$do[pulse_rows] <- baseline_do + heat_response * 1.2 + rnorm(150, 0, 0.02)
  measurements$di[pulse_rows] <- baseline_di + heat_response * 1.0 + rnorm(150, 0, 0.02)
  measurements$uo[pulse_rows] <- baseline_uo + heat_response * 0.8 + rnorm(150, 0, 0.01)
  measurements$ui[pulse_rows] <- baseline_ui + heat_response * 0.7 + rnorm(150, 0, 0.01)
}

# Create diagnostic data
diagnostics <- data.frame(
  pulse_id = 1:n_pulses,
  datetime = seq(as.POSIXct("2024-03-15 08:00:00"), by = "30 min", length.out = n_pulses),
  batt_volt = runif(n_pulses, 3.9, 4.1),
  batt_current = c(rnorm(n_pulses-1, 15, 2), rnorm(1, 180, 10)),  # One high heating pulse
  batt_temp = rnorm(n_pulses, 25, 2),
  external_volt = rnorm(n_pulses, 21, 1),
  external_current = c(rnorm(n_pulses-1, 18, 2), rnorm(1, 75, 5))
)

# Create heat_pulse_data object
heat_pulse_data <- list(
  measurements = measurements,
  diagnostics = diagnostics,
  metadata = list(
    file_path = "example_data.txt",
    file_name = "example_data.txt",
    format = "ict_current",
    import_time = Sys.time(),
    file_size = 125000,
    file_size_mb = 0.12,
    n_pulses = n_pulses,
    n_measurements = nrow(measurements),
    chunk_size = 100000,
    r_version = paste(R.version$major, R.version$minor, sep = "."),
    package_version = "0.2.0"
  )
)
class(heat_pulse_data) <- c("heat_pulse_data", "list")
```

### Inspect Imported Data

```{r}
# Summary of imported data
str(heat_pulse_data, max.level = 2)

# View first few temperature measurements
head(heat_pulse_data$measurements)

# View diagnostic information
head(heat_pulse_data$diagnostics)
```

### (Optional) Correct for Clock Drift

If you notice the device clock has drifted (common with long deployments), you can correct timestamps before processing:

```{r eval=FALSE}
# Example: Device was 5 minutes fast when retrieved on 2025-01-16 08:00:00
# The device displayed 2025-01-16 08:05:00 at that moment

# Fix clock drift - pass the entire heat_pulse_data object
heat_pulse_data <- fix_clock_drift(
  data = heat_pulse_data,
  observed_device_time = as.POSIXct("2025-01-16 08:05:00", tz = "UTC"),
  observed_actual_time = as.POSIXct("2025-01-16 08:00:00", tz = "UTC")
)

# This automatically corrects both measurements and diagnostics
# Original timestamps are preserved in 'device_datetime' column
# Corrected timestamps replace the 'datetime' column
```

**How it works:**
- Assumes the device clock was accurate at deployment (dataset start)
- Applies a linear correction based on a single calibration point
- Preserves original timestamps in a `device_datetime` column
- Stores correction metadata as attributes for traceability

See `?fix_clock_drift` for full details and advanced options.

## 2. Calculate Heat Pulse Velocity

Calculate sap velocity using one or more established methods:

```{r}
# Calculate using multiple methods
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  show_progress = FALSE
)

# View results
head(vh_results)
```

### Available Calculation Methods

| Method | Best For | Reference |
|--------|----------|-----------|
| **HRM** | Low flows, reverse flows | Burgess et al. (2001) |
| **MHR** | Moderate flows | Lopez et al. (2021) |
| **HRMXa/b** | Enhanced HRM accuracy | Burgess & Bleby (unpublished) |
| **Tmax_Coh** | High flows | Cohen et al. (1981) |
| **Tmax_Klu** | High flows (adjusted) | Kluitenberg & Ham (2004) |

<!-- sDMA NOTE REMOVED - functionality being re-implemented in later workflow stage -->
<!-- **Note:** DMA (Dual Method Approach) is applied as post-processing using `apply_sdma_processing()` - see section below. -->

### Understanding the Output

```{r}
# Results structure
colnames(vh_results)

# Quality flags
table(vh_results$quality_flag)

# Summary by method
aggregate(Vh_cm_hr ~ method, data = vh_results, FUN = function(x) {
  c(mean = mean(x, na.rm = TRUE),
    sd = sd(x, na.rm = TRUE),
    n = sum(!is.na(x)))
})
```

### Two-Tier Quality Flag System

sapfluxr uses a **two-tier quality flag system** to distinguish between different types of data issues:

**Tier 1 - Calculation Quality (CALC_ prefix):**
Set during `calc_heat_pulse_velocity()`, indicates issues with the calculation itself:

- `CALC_FAILED` - Calculation returned NA (e.g., Tmax couldn't find peak)
- `CALC_INFINITE` - Calculation returned Inf (division by zero, etc.)
- `CALC_EXTREME` - Result outside physically realistic range

**Tier 2 - Data Quality (DATA_ prefix):**
Set during `flag_vh_quality()`, indicates issues with time series patterns:

- `DATA_MISSING` - No pulse recorded at expected timestamp
- `DATA_ILLOGICAL` - Exceeds hard maximum or species-specific thresholds
- `DATA_OUTLIER` - Statistical outlier (rolling median or rate of change)
- `DATA_SUSPECT` - Negative flow or cross-sensor anomaly

**OK** - No issues detected in either tier

```{r}
# View only high-quality results
good_results <- vh_results[vh_results$quality_flag == "OK", ]
nrow(good_results)

# View problematic results
bad_results <- vh_results[vh_results$quality_flag != "OK", ]
table(bad_results$quality_flag, bad_results$method)
```

## 2a. Quality Control and Outlier Detection

After calculating velocities, apply comprehensive quality control to detect missing data, outliers, and suspicious patterns:

```{r eval=FALSE}
# Apply quality control with default settings
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",  # Optional: species-specific thresholds
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE,
  detect_rate_of_change = TRUE
)

# View flagged data
vh_flagged <- qc_results$vh_flagged
table(vh_flagged$quality_flag)

# View gap report (missing data periods)
print(qc_results$gap_report)

# View outlier summary
print(qc_results$outlier_summary)
```

**What `flag_vh_quality()` detects:**

1. **Missing Pulses** - Detects gaps in time series and optionally adds DATA_MISSING rows
2. **Illogical Values** - Flags velocities exceeding hard maximum (500 cm/hr) or species-specific thresholds
3. **Statistical Outliers** - Uses rolling median (default 11-point window) to detect spikes
4. **Excessive Rate of Change** - Flags jumps > 4 cm/hr between consecutive measurements
5. **Cross-Sensor Anomalies** - Compares sensors at same timestamp to detect sensor failures
6. **Negative Flows** - Flags as SUSPECT (may be real reverse flows or sensor issues)

**Customise detection sensitivity:**

```{r eval=FALSE}
# More sensitive outlier detection
qc_results <- flag_vh_quality(
  vh_results,
  rolling_window = 7,           # Wider window (15 points total)
  rolling_threshold = 2.5,      # More sensitive (default: 3 MAD)
  max_change_cm_hr = 3,         # Stricter rate of change (default: 4)
  max_gap_to_fill_hours = 12    # Don't fill gaps > 12 hours (default: 24)
)
```

**Why simple methods work:**
Sap flow data typically has regular measurement intervals and gradual changes. Rolling median and rate-of-change detection effectively catch sensor spikes and logging errors without needing complex seasonal decomposition.

**Handling large gaps:**
Gaps larger than `max_gap_to_fill_hours` are reported in `gap_report` but NOT filled with MISSING rows to avoid creating thousands of entries. Only small gaps are filled.

See `?flag_vh_quality` for full details.

## 2b. Zero-Flow Correction (Spacing Adjustment)

### Why Zero-Flow Correction?

Heat pulse velocity sensors can experience **probe spacing errors** due to:
- Slight misalignment during installation
- Tree swelling/shrinking with moisture changes
- Bark expansion after rain events
- Seasonal wood movement

These spacing errors cause **systematic bias** in velocity estimates. During periods of true zero flow (no transpiration), misaligned probes will still report non-zero velocities.

**The Burgess et al. (2001) correction** uses zero-flow calibration periods to:
1. Calculate the apparent velocity when true flow is zero (the "zero offset")
2. Derive correction coefficients that account for probe misalignment
3. Apply a linear correction to all velocity measurements

### Workflow 1: Manual Zero-Flow Period Definition

This is the **recommended approach** when you have known zero-flow conditions:

```{r eval=FALSE}
# Step 1: Define zero-flow periods (times when transpiration was truly zero)
# Examples: extended rain events, winter dormancy, cut trees
zero_periods <- list(
  list(start = "2024-05-01 00:00:00", end = "2024-05-05 23:59:59"),  # 5-day rain event
  list(start = "2024-08-15 02:00:00", end = "2024-08-15 06:00:00")  # Pre-dawn period
)

# Step 2: Apply complete spacing correction workflow
correction_result <- apply_spacing_correction_workflow(
  vh_data = vh_results,
  zero_periods = zero_periods,
  sensors = c("outer", "inner"),    # Correct both sensors
  method = "HRM",                    # Method to correct
  k_assumed = 0.0025,                # Thermal diffusivity (cm²/s)
  verbose = TRUE                     # Print detailed progress
)

# Step 3: Extract corrected data
vh_corrected <- correction_result$vh_corrected

# View correction summary
print(correction_result)
```

**Choosing Good Zero-Flow Periods:**

✅ **Excellent candidates:**
- Extended rain events (3-7 days) with overcast skies
- Winter periods for deciduous trees (leafless, dormant)
- Freshly cut trees (first few hours after cutting)
- Multi-day cloudy periods with high humidity

⚠️ **Poor candidates:**
- Single nighttime periods (may have nocturnal flow)
- Brief rain events (< 6 hours)
- Periods immediately after rain (bark swelling in progress)

**Quality Indicators:**
- **CV < 0.3** - Excellent stability, high confidence
- **CV 0.3-0.5** - Acceptable, moderate confidence
- **CV > 0.5** - High variability, consider different periods

```{r eval=FALSE}
# Check correction quality
correction_result$zero_offset_results$outer$overall_cv  # Should be < 0.3

# View per-period statistics
correction_result$zero_offset_results$outer$period_summary
```

### Workflow 2: Automatic Zero-Flow Detection

If you don't have known zero-flow periods, use automatic detection:

```{r eval=FALSE}
# Detect candidate zero-flow periods automatically
candidates <- detect_zero_flow_periods(
  vh_data = vh_results,
  sensor_position = "outer",
  method = "HRM",
  detection_method = "weekly",        # Options: "weekly", "monthly", "statistical", "all"
  min_period_hours = 6,               # Minimum duration
  max_velocity_threshold = 2.0,       # cm/hr (low velocities)
  max_cv_threshold = 0.3,             # Stable periods only
  max_candidates = 10                 # Top 10 candidates
)

# View candidates ranked by quality score
head(candidates)

# Select excellent candidates only
excellent <- candidates[candidates$recommendation == "excellent", ]

# Convert to zero_periods format
zero_periods <- lapply(1:nrow(excellent), function(i) {
  list(
    start = format(excellent$start[i], "%Y-%m-%d %H:%M:%S"),
    end = format(excellent$end[i], "%Y-%m-%d %H:%M:%S")
  )
})

# Apply correction using detected periods
correction_result <- apply_spacing_correction_workflow(
  vh_data = vh_results,
  zero_periods = zero_periods,
  sensors = c("outer", "inner"),
  method = "HRM"
)
```

**Detection Methods:**
- **"weekly"** - Finds weekly minimum flow periods (good for regular environmental cycles)
- **"monthly"** - Identifies monthly minimums (good for seasonal zero-flow)
- **"statistical"** - Uses velocity + CV thresholds (most flexible)
- **"all"** - Tries all methods and returns best candidates

### Workflow 3: Changepoint-Based Correction

For long deployments where probe alignment changes over time (tree swelling, seasonal movement), use **changepoint detection** to apply different corrections to different time periods:

```{r eval=FALSE}
# Step 1: Calculate daily minimum velocities
daily_min <- calculate_daily_minima(
  vh_data = vh_results,
  sensor_position = "outer",
  method = "HRM"
)

# Step 2: Detect changepoints (baseline shifts indicating probe movement)
cpt_result <- detect_changepoints(
  daily_min = daily_min,
  penalty = "MBIC",                  # Options: "MBIC" (conservative), "BIC", "Manual"
  detection_type = "mean",           # Detect mean changes (baseline shifts)
  min_segment_days = 7,              # Minimum segment length
  merge_short_segments = TRUE        # Merge spurious short segments
)

# View detected changepoints
print(cpt_result$changepoints)
print(cpt_result$segments)

# Step 3: Get segment baselines
segments_with_baselines <- extract_segment_baselines(cpt_result)

# Step 4: Apply correction per segment
segment_correction <- apply_spacing_correction_per_segment(
  vh_data = vh_results,
  changepoints = cpt_result$changepoints,
  sensor_position = "outer",
  method = "HRM",
  k_assumed = 0.0025
)

vh_corrected <- segment_correction$vh_corrected
```

**When to Use Changepoint-Based Correction:**
- Long deployments (> 3 months)
- Data spans wet/dry seasonal transitions
- Visible baseline shifts in daily minimum plots
- Trees known to have significant swelling/shrinking

**Penalty Selection:**
- **MBIC** (recommended) - Most conservative, fewest changepoints
- **BIC** - Moderate, more changepoints than MBIC
- **Manual** (e.g., `penalty_value = 50`) - Full control over sensitivity

### Diagnostic Plots

Visualise zero-flow periods and correction impacts:

```{r eval=FALSE}
# Plot zero-flow period selection
plot_zero_flow_periods(
  vh_data = vh_results,
  zero_periods = zero_periods,
  sensor_position = "outer",
  method = "HRM",
  show_stats = TRUE
)

# Compare before/after correction
plot_spacing_correction_comparison(
  spacing_result = correction_result,
  sensor_position = "outer",
  show_difference = TRUE
)

# View Burgess coefficient lookup curves
lookup <- calculate_burgess_coefficients()
plot_burgess_coefficients(
  lookup_table = lookup,
  zero_vh_observed = c(0.8, 1.2),  # Your observed zero offsets
  labels = c("Outer", "Inner")
)

# Interactive changepoint visualisation
plot_changepoints_interactive(
  daily_min = cpt_result$daily_min_with_segments,
  changepoints = cpt_result$changepoints,
  segments = segments_with_baselines,
  show_baseline_values = TRUE
)
```

### Understanding Correction Results

```{r eval=FALSE}
# Correction formula for each sensor
correction_result$correction_coefficients$outer
# Output example:
#   zero_vh: 0.8 cm/hr
#   coef_a: 1.0234 (slope)
#   coef_b: -0.8192 (offset)
#   severity: "minor"
#
# Corrected_Vh = 1.0234 × Vh - 0.8192

# Compare uncorrected vs corrected
summary(vh_results$Vh_cm_hr[vh_results$sensor_position == "outer"])
summary(vh_corrected$Vh_cm_hr_sc[vh_corrected$sensor_position == "outer"])
```

**Severity Assessment:**

| Zero Offset | Severity | Interpretation |
|-------------|----------|----------------|
| ≤ 1 cm/hr | None/Minor | Typical field installation |
| 1-3 cm/hr | Minor | Acceptable, correction reliable |
| 3-5 cm/hr | Moderate | Significant misalignment |
| 5-10 cm/hr | Severe | Major misalignment, elevated uncertainty |
| > 10 cm/hr | Critical | **Discard data, reinstall probes** |

### Best Practices

1. **Always correct BEFORE downstream analyses** (sDMA, flux scaling, etc.)
2. **Use multiple zero-flow periods** (2-5) from different conditions
3. **Each period should be ≥ 6-12 hours** for stable statistics
4. **Check CV values** - aim for CV < 0.3 for high confidence
5. **Correct both sensors independently** - they may have different offsets
6. **Document your zero-flow period selection** in metadata
7. **Create diagnostic plots** to visually confirm period quality

### Integration with Quality Control

Spacing correction should be applied **after** quality flagging but **before** method-switching (sDMA):

```{r eval=FALSE}
# Recommended workflow order:
# 1. Calculate velocities
vh_results <- calc_heat_pulse_velocity(heat_pulse_data, methods = "HRM")

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Spacing correction (THIS STEP)
correction_result <- apply_spacing_correction_workflow(
  vh_data = vh_flagged,
  zero_periods = zero_periods,
  sensors = c("outer", "inner"),
  method = "HRM"
)
vh_corrected <- correction_result$vh_corrected

# 4. Now apply sDMA or other post-processing
vh_final <- apply_sdma_processing(vh_corrected, secondary_method = "MHR")
```

See `?apply_spacing_correction_workflow`, `?detect_changepoints`, and `?calculate_zero_offset` for detailed parameter documentation.
## 3. Visualise Results

### Time Series Plot

```{r fig.width=8, fig.height=5}
# Plot velocity time series
plot_vh_timeseries(
  vh_results,
  methods = c("HRM", "MHR", "HRMXa"),
  sensor_position = "outer"
)
```

### Heat Pulse Trace Plot

Visualise individual heat pulse responses and see exactly where each method calculated its result:

```{r fig.width=8, fig.height=6}
# Plot trace for a single pulse
plot_heat_pulse_trace(
  heat_pulse_data,
  vh_results,
  pulse_id = 5,
  show_methods = c("HRM", "HRMXa", "Tmax_Klu")
)
```

The shaded regions and markers show which time points each method used for its calculation:
- **HRM**: Grey shaded window showing averaging period
- **HRMXa**: Blue shaded window showing averaging period
- **HRMXb**: Green shaded window showing averaging period
- **MHR**: Orange shaded window showing time span from upstream to downstream peak, with orange points and lines marking both upstream and downstream peaks
- **Tmax methods**: Dark green vertical line and point marking time to maximum temperature

This is invaluable for:
- Understanding why methods give different results
- Diagnosing problematic pulses
- Validating calculation windows
- Visualizing the temporal dynamics of heat pulse transport

### Method Comparison

```{r fig.width=8, fig.height=6}
# Compare two methods across all pulses
plot_method_comparison(
  vh_results,
  method1 = "HRM",
  method2 = "MHR",
  sensor_position = "outer"
)
```

<!-- ============================================================================ -->
<!-- sDMA SECTION - TEMPORARILY REMOVED                                         -->
<!--                                                                             -->
<!-- The Selectable Dual Method Approach (sDMA) functionality has been          -->
<!-- temporarily extracted from the active workflow and is being re-implemented -->
<!-- in a later workflow stage.                                                 -->
<!--                                                                             -->
<!-- FUTURE POSITION: sDMA will be available after wound correction and before  -->
<!-- flux density calculation (between Steps 4 and 5).                          -->
<!--                                                                             -->
<!-- FUTURE FUNCTIONALITY:                                                      -->
<!-- - Will apply to corrected velocities (Vc) instead of raw velocities (Vh)  -->
<!-- - Will use Peclet numbers calculated from corrected HRM results            -->
<!-- - Will allow switching between HRM and secondary methods based on Pe       -->
<!--                                                                             -->
<!-- Complete implementation preserved in: R/04j_sdma_methods.R                 -->
<!-- See: SDMA_EXTRACTION_STATUS.md for extraction status and timeline          -->
<!-- ============================================================================ -->

<!--
## Selectable Dual Method Approach (sDMA)

The **Selectable DMA** (sDMA) is an advanced post-processing method that allows you to choose which high-flow method to pair with HRM. This provides an automatic method selection based on flow conditions.

### How sDMA Works

sDMA automatically switches between two methods based on the **Peclet number (Pe)**:

- **Pe < 1.0**: Uses HRM (optimal for low flows)
- **Pe ≥ 1.0**: Uses your chosen secondary method (optimal for high flows)

The Peclet number is calculated from the HRM velocity: `Pe = (Vh_HRM × probe_spacing) / (diffusivity × 3600)`

### Why Post-Processing?

**New Workflow (Efficient):**
```{r eval=FALSE}
# Step 1: Calculate base methods (each calculated once)
vh <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "Tmax_Klu")
)

# Step 2: Apply sDMA switching as post-processing
vh_sdma <- apply_sdma_processing(vh, secondary_method = "MHR")

# Now have: HRM, MHR, Tmax_Klu, sDMA:MHR (all in one tibble)
```

**Benefits:**
- Each method calculated exactly once (no redundancy)
- Can apply sDMA after corrections: `apply_hpv_corrections() %>% apply_sdma_processing()`
- Can test multiple secondary methods without recalculating HRM
- More explicit about what's happening

### Using sDMA

```{r}
# Step 1: Calculate base methods including HRM (required for Peclet numbers)
vh <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR"),
  show_progress = FALSE
)

# Step 2: Apply sDMA processing with MHR as secondary method
vh_sdma <- apply_sdma_processing(
  vh,
  secondary_method = "MHR",
  show_progress = FALSE
)

# View sDMA-specific columns
head(vh_sdma[vh_sdma$method == "sDMA:MHR",
             c("datetime", "method", "Vh_cm_hr",
               "peclet_number", "selected_method")])
```

The `selected_method` column shows which method was actually used for each measurement (HRM or MHR).

### Compare Multiple sDMA Variants

You can test multiple secondary methods to find which works best for your data:

```{r}
# Calculate base methods once
vh <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "Tmax_Klu"),
  show_progress = FALSE
)

# Apply sDMA with multiple secondary methods at once
vh_multi_sdma <- apply_sdma_processing(
  vh,
  secondary_method = c("MHR", "Tmax_Klu"),
  show_progress = FALSE
)

# Now have: HRM, MHR, Tmax_Klu, sDMA:MHR, sDMA:Tmax_Klu
unique(vh_multi_sdma$method)

# Summary by method
aggregate(Vh_cm_hr ~ method, data = vh_multi_sdma, FUN = mean, na.rm = TRUE)
```

### Visualising sDMA Results

The dedicated sDMA plotting function shows:

- Velocity points colored by which method was selected (HRM vs secondary)
- Peclet number on a secondary y-axis (grey line)
- The Pe = 1.0 switching threshold (dashed horizontal line)
- Legend includes both selected methods and the Peclet number line

```{r fig.width=8, fig.height=6, eval=FALSE}
# Plot sDMA time series with Peclet number
plot_sdma_timeseries(
  vh_sdma,
  sdma_method = "sDMA:MHR",
  sensor_position = "outer"
)

# Plot without Peclet number
plot_sdma_timeseries(
  vh_sdma,
  sdma_method = "sDMA:MHR",
  sensor_position = "outer",
  show_peclet = FALSE
)
```

The plot legend shows which method was used for each data point (and the Peclet number when `show_peclet = TRUE`), and the summary statistics tell you what percentage of measurements used HRM vs the secondary method.

### When to Use sDMA

Use sDMA when:

- **You have variable flow conditions**: Data spans both low and high flow regimes
- **You want method transparency**: sDMA shows exactly which method was used via `selected_method` column
- **Tmax methods fail frequently**: Try `sDMA:MHR` as an alternative to standard DMA (which uses Tmax_Klu)
- **You want to analyse flow regimes**: The `peclet_number` column reveals flow conditions over time

### Advanced: sDMA After Corrections

The post-processing approach allows you to apply sDMA after making probe corrections:

```{r eval=FALSE}
# Calculate base methods
vh <- calc_heat_pulse_velocity(heat_pulse_data, methods = c("HRM", "MHR"))

# Apply corrections (wound diameter, zero-flow, etc.)
vh_corrected <- apply_hpv_corrections(vh, corrections)

# Then apply sDMA to corrected results
vh_sdma <- apply_sdma_processing(vh_corrected, secondary_method = "MHR")
```
-->

# Configurations

## Wood Properties

Wood properties affect thermal calculations. Use built-in configurations or create custom ones:

```{r eval=FALSE}
# Use built-in configurations
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus"  # or "pine", "generic_sw"
)

# Override specific properties
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus",
  wood_overrides = list(
    thermal_diffusivity = 0.0028,  # cm²/s
    dbh = 45.2,                    # cm
    sapwood_depth = 3.5            # cm
  )
)
```

### Create Custom Wood Properties

Create a YAML file with your species-specific properties:

```yaml
# wood_my_species.yaml
species:
  common_name: "My Species"
  scientific_name: "Genus species"

thermal_properties:
  thermal_diffusivity:
    value: 0.0025
    units: "cm²/s"
    source: "Measured from cores"

  thermal_conductivity:
    value: 0.0050
    units: "W/(m·K)"

  volumetric_heat_capacity:
    value: 2.0
    units: "MJ/(m³·K)"

physical_properties:
  wood_density:
    value: 550
    units: "kg/m³"

  moisture_content:
    value: 0.40
    units: "fraction"

tree_measurements:
  dbh:
    value: 35.0
    units: "cm"

  sapwood_depth:
    value: 2.8
    units: "cm"
```

Load your custom configuration:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "path/to/wood_my_species.yaml"
)
```

## Probe Configuration

Probe configurations define hardware specifications:

```{r eval=FALSE}
# Use default symmetric probe (ICT SFM1x standard)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "symmetrical"  # Default
)

# Use asymmetric probe (CHPM optimised)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "asymmetrical"
)
```

### Create Custom Probe Configuration

For custom probe geometries:

```yaml
# probe_custom.yaml
probe_type: "custom_probe"
description: "Custom probe geometry"

geometry:
  probe_spacing:
    value: 0.6
    units: "cm"

  probe_diameter:
    value: 1.5
    units: "mm"

  thermistor_positions:
    downstream_outer: 0.6   # cm from heater
    downstream_inner: 0.3
    upstream_outer: -0.6
    upstream_inner: -0.3

measurement:
  heat_pulse_duration:
    value: 2.0
    units: "seconds"
```

# Advanced Topics

## Custom Calculation Parameters

Override default calculation windows:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = "HRM",
  parameters = list(
    pre_pulse = 30,      # Baseline period (sec)
    HRM_start = 70,      # HRM window start (sec)
    HRM_end = 110,       # HRM window end (sec)
    L = 0.5,             # HRMX lower bound (proportion of max temp)
    H = 0.8              # HRMX upper bound
  )
)
```

## Filter by Quality

The two-tier quality flag system (CALC_ and DATA_ prefixes) helps identify different types of issues:

```{r}
# Keep only high-quality results (no calculation or data issues)
good_results <- vh_results[vh_results$quality_flag == "OK", ]

# View all quality flags
table(vh_results$quality_flag, vh_results$method)

# Filter out calculation failures but keep data quality issues for manual review
calc_ok <- vh_results[!grepl("^CALC_", vh_results$quality_flag), ]

# After running flag_vh_quality(), you can filter by both tiers
# qc_results <- flag_vh_quality(vh_results)
# clean_data <- qc_results$vh_flagged[qc_results$vh_flagged$quality_flag == "OK", ]
```

## Export Results

```{r eval=FALSE}
# Export to CSV
write.csv(vh_results, "sap_velocity_results.csv", row.names = FALSE)

# Export with metadata
saveRDS(list(
  results = vh_results,
  metadata = heat_pulse_data$metadata,
  processing_date = Sys.time()
), "sap_velocity_complete.rds")
```

# Workflow Summary

```r
# Complete workflow with all quality control steps
library(sapfluxr)

# 1. Import
heat_pulse_data <- read_heat_pulse_data("mydata.txt")

# 1a. (Optional) Fix clock drift if detected
# heat_pulse_data <- fix_clock_drift(
#   data = heat_pulse_data,
#   observed_device_time = as.POSIXct("2025-01-16 08:05:00"),
#   observed_actual_time = as.POSIXct("2025-01-16 08:00:00")
# )

# 2. Calculate velocities
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  wood_properties = "eucalyptus"
)

# 2a. Apply quality control
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE
)
vh_flagged <- qc_results$vh_flagged

# 2b. (Optional) Apply sDMA post-processing
vh_sdma <- apply_sdma_processing(vh_flagged, secondary_method = "MHR")

# 3. Visualise
plot_vh_timeseries(vh_flagged, methods = c("HRM", "MHR", "HRMXa"))
plot_heat_pulse_trace(heat_pulse_data, vh_flagged, pulse_id = 1)
plot_sdma_timeseries(vh_sdma, sdma_method = "sDMA:MHR")

# 4. Export (only OK quality data)
clean_data <- vh_flagged[vh_flagged$quality_flag == "OK", ]
write.csv(clean_data, "sap_velocity_clean.csv", row.names = FALSE)
```

## Common Workflows

### Standard Analysis
```r
# Use proven methods for routine analysis
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "DMA")
)
```

### Method Comparison
```r
# Compare multiple methods to find the best for your data
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu", "DMA")
)
```

### sDMA Optimisation
```r
# If standard DMA has issues, try different secondary methods
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("DMA", "sDMA:MHR", "sDMA:Tmax_Klu", "sDMA:HRMXa")
)

# Visualise each variant
plot_sdma_timeseries(vh_results, sdma_method = "sDMA:MHR")
plot_sdma_timeseries(vh_results, sdma_method = "sDMA:HRMXa")
```

# Getting Help

- **Package documentation**: `?calc_heat_pulse_velocity`
- **Report issues**: https://github.com/neez777/sapfluxr/issues
- **Method details**: See `knowledge_docs/` in package installation

# References

- Burgess, S. S. O., Adams, M. A., Turner, N. C., Beverly, C. R., Ong, C. K., Khan, A. A. H., & Bleby, T. M. (2001). An improved heat pulse method to measure low and reverse rates of sap flow in woody plants. *Tree Physiology*, 21(9), 589-598.

- Cohen, Y., Fuchs, M., & Green, G. C. (1981). Improvement of the heat pulse method for determining sap flow in trees. *Plant, Cell & Environment*, 4(5), 391-397.

- Forster, M. A. (2020). How significant is nocturnal sap flow? *Tree Physiology*, 40(8), 1179-1190.

- Kluitenberg, G. J., & Ham, J. M. (2004). Improved theory for calculating sap flow with the heat pulse method. *Agricultural and Forest Meteorology*, 126(1-2), 169-173.

- Lopez, J. G., Morán-López, T., Benito Garzón, M., & Oliveras Menor, I. (2021). An improved heat pulse method using a single probe for determining sap flow in temperate trees. *Tree Physiology*, 41(12), 2437-2449.
