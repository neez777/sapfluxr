---
title: "Quick Start Guide to sapfluxr"
author: "Grant Joyce"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Quick Start Guide to sapfluxr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

# Introduction

**sapfluxr** processes and analyses sap flow data from ICT SFM1x heat pulse velocity (HPV) sensors. This guide walks you through the complete workflow from raw data to visualised results.

## Installation

```{r eval=FALSE}
# Install from GitHub
devtools::install_github("neez777/sapfluxr")
```

```{r}
library(sapfluxr)
library(ggplot2)  # For plotting
```

# Basic Workflow

## 1. Import Data

sapfluxr automatically detects and imports multiple data formats from ICT sensors:

```{r eval=FALSE}
# Import raw heat pulse data
heat_pulse_data <- read_heat_pulse_data("path/to/your/data.txt")
```

The import function will:
- Auto-detect the file format (ICT current, legacy, or CSV)
- Parse temperature measurements from all four thermistors (do, di, uo, ui)
- Extract diagnostic information (battery voltage, temperature, etc.)
- Validate data quality (if `validate_data = TRUE`)

```{r include=FALSE}
# Create example data for this vignette
set.seed(42)
n_pulses <- 10

# Simulate realistic temperature data
measurements <- data.frame(
  pulse_id = rep(1:n_pulses, each = 150),
  datetime = rep(seq(as.POSIXct("2024-03-15 08:00:00"),
                     by = "30 min", length.out = n_pulses), each = 150)
)

# Add time within each pulse
measurements$datetime <- measurements$datetime + rep(0:149, times = n_pulses)

# Simulate temperature data with realistic heat pulse response
for (i in 1:n_pulses) {
  pulse_rows <- (i-1)*150 + 1:150
  time_sec <- 0:149

  # Pre-pulse baseline temperatures
  baseline_do <- 18.5 + rnorm(1, 0, 0.1)
  baseline_di <- 18.4 + rnorm(1, 0, 0.1)
  baseline_uo <- 18.6 + rnorm(1, 0, 0.1)
  baseline_ui <- 18.3 + rnorm(1, 0, 0.1)

  # Heat pulse response (rises after 30 sec, peaks around 60-80 sec, decays)
  heat_response <- ifelse(time_sec < 30, 0,
                          exp(-(time_sec - 60)^2 / 800) * runif(1, 0.8, 1.2))

  measurements$do[pulse_rows] <- baseline_do + heat_response * 1.2 + rnorm(150, 0, 0.02)
  measurements$di[pulse_rows] <- baseline_di + heat_response * 1.0 + rnorm(150, 0, 0.02)
  measurements$uo[pulse_rows] <- baseline_uo + heat_response * 0.8 + rnorm(150, 0, 0.01)
  measurements$ui[pulse_rows] <- baseline_ui + heat_response * 0.7 + rnorm(150, 0, 0.01)
}

# Create diagnostic data
diagnostics <- data.frame(
  pulse_id = 1:n_pulses,
  datetime = seq(as.POSIXct("2024-03-15 08:00:00"), by = "30 min", length.out = n_pulses),
  batt_volt = runif(n_pulses, 3.9, 4.1),
  batt_current = c(rnorm(n_pulses-1, 15, 2), rnorm(1, 180, 10)),  # One high heating pulse
  batt_temp = rnorm(n_pulses, 25, 2),
  external_volt = rnorm(n_pulses, 21, 1),
  external_current = c(rnorm(n_pulses-1, 18, 2), rnorm(1, 75, 5))
)

# Create heat_pulse_data object
heat_pulse_data <- list(
  measurements = measurements,
  diagnostics = diagnostics,
  metadata = list(
    file_path = "example_data.txt",
    file_name = "example_data.txt",
    format = "ict_current",
    import_time = Sys.time(),
    file_size = 125000,
    file_size_mb = 0.12,
    n_pulses = n_pulses,
    n_measurements = nrow(measurements),
    chunk_size = 100000,
    r_version = paste(R.version$major, R.version$minor, sep = "."),
    package_version = "0.2.0"
  )
)
class(heat_pulse_data) <- c("heat_pulse_data", "list")
```

### Inspect Imported Data

```{r}
# Summary of imported data
str(heat_pulse_data, max.level = 2)

# View first few temperature measurements
head(heat_pulse_data$measurements)

# View diagnostic information
head(heat_pulse_data$diagnostics)
```

### (Optional) Correct for Clock Drift

If you notice the device clock has drifted (common with long deployments), you can correct timestamps before processing:

```{r eval=FALSE}
# Example: Device was 5 minutes fast when retrieved on 2025-01-16 08:00:00
# The device displayed 2025-01-16 08:05:00 at that moment

# Fix clock drift - pass the entire heat_pulse_data object
heat_pulse_data <- fix_clock_drift(
  data = heat_pulse_data,
  observed_device_time = as.POSIXct("2025-01-16 08:05:00", tz = "UTC"),
  observed_actual_time = as.POSIXct("2025-01-16 08:00:00", tz = "UTC")
)

# This automatically corrects both measurements and diagnostics
# Original timestamps are preserved in 'device_datetime' column
# Corrected timestamps replace the 'datetime' column
```

**How it works:**
- Assumes the device clock was accurate at deployment (dataset start)
- Applies a linear correction based on a single calibration point
- Preserves original timestamps in a `device_datetime` column
- Stores correction metadata as attributes for traceability

See `?fix_clock_drift` for full details and advanced options.

## 2. Calculate Heat Pulse Velocity

Calculate sap velocity using one or more established methods:

```{r}
# Calculate using multiple methods
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  show_progress = FALSE
)

# View results
head(vh_results)
```

### Available Calculation Methods

| Method | Best For | Reference |
|--------|----------|-----------|
| **HRM** | Low flows, reverse flows | Burgess et al. (2001) |
| **MHR** | Moderate flows | Lopez et al. (2021) |
| **HRMXa/b** | Enhanced HRM accuracy | Burgess & Bleby (unpublished) |
| **Tmax_Coh** | High flows | Cohen et al. (1981) |
| **Tmax_Klu** | High flows (adjusted) | Kluitenberg & Ham (2004) |

<!-- sDMA NOTE REMOVED - functionality being re-implemented in later workflow stage -->
<!-- **Note:** DMA (Dual Method Approach) is applied as post-processing using `apply_sdma_processing()` - see section below. -->

### Understanding the Output

```{r}
# Results structure
colnames(vh_results)

# Quality flags
table(vh_results$quality_flag)

# Summary by method
aggregate(Vh_cm_hr ~ method, data = vh_results, FUN = function(x) {
  c(mean = mean(x, na.rm = TRUE),
    sd = sd(x, na.rm = TRUE),
    n = sum(!is.na(x)))
})
```

### Two-Tier Quality Flag System

sapfluxr uses a **two-tier quality flag system** to distinguish between different types of data issues:

**Tier 1 - Calculation Quality (CALC_ prefix):**
Set during `calc_heat_pulse_velocity()`, indicates issues with the calculation itself:

- `CALC_FAILED` - Calculation returned NA (e.g., Tmax couldn't find peak)
- `CALC_INFINITE` - Calculation returned Inf (division by zero, etc.)
- `CALC_EXTREME` - Result outside physically realistic range

**Tier 2 - Data Quality (DATA_ prefix):**
Set during `flag_vh_quality()`, indicates issues with time series patterns:

- `DATA_MISSING` - No pulse recorded at expected timestamp
- `DATA_ILLOGICAL` - Exceeds hard maximum or species-specific thresholds
- `DATA_OUTLIER` - Statistical outlier (rolling median or rate of change)
- `DATA_SUSPECT` - Negative flow or cross-sensor anomaly

**OK** - No issues detected in either tier

```{r}
# View only high-quality results
good_results <- vh_results[vh_results$quality_flag == "OK", ]
nrow(good_results)

# View problematic results
bad_results <- vh_results[vh_results$quality_flag != "OK", ]
table(bad_results$quality_flag, bad_results$method)
```

## 2a. Quality Control and Outlier Detection

After calculating velocities, apply comprehensive quality control to detect missing data, outliers, and suspicious patterns:

```{r eval=FALSE}
# Apply quality control with default settings
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",  # Optional: species-specific thresholds
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE,
  detect_rate_of_change = TRUE
)

# View flagged data
vh_flagged <- qc_results$vh_flagged
table(vh_flagged$quality_flag)

# View gap report (missing data periods)
print(qc_results$gap_report)

# View outlier summary
print(qc_results$outlier_summary)
```

**What `flag_vh_quality()` detects:**

1. **Missing Pulses** - Detects gaps in time series and optionally adds DATA_MISSING rows
2. **Illogical Values** - Flags velocities exceeding hard maximum (500 cm/hr) or species-specific thresholds
3. **Statistical Outliers** - Uses rolling median (default 11-point window) to detect spikes
4. **Excessive Rate of Change** - Flags jumps > 4 cm/hr between consecutive measurements
5. **Cross-Sensor Anomalies** - Compares sensors at same timestamp to detect sensor failures
6. **Negative Flows** - Flags as SUSPECT (may be real reverse flows or sensor issues)

**Customise detection sensitivity:**

```{r eval=FALSE}
# More sensitive outlier detection
qc_results <- flag_vh_quality(
  vh_results,
  rolling_window = 7,           # Wider window (15 points total)
  rolling_threshold = 2.5,      # More sensitive (default: 3 MAD)
  max_change_cm_hr = 3,         # Stricter rate of change (default: 4)
  max_gap_to_fill_hours = 12    # Don't fill gaps > 12 hours (default: 24)
)
```

**Why simple methods work:**
Sap flow data typically has regular measurement intervals and gradual changes. Rolling median and rate-of-change detection effectively catch sensor spikes and logging errors without needing complex seasonal decomposition.

**Handling large gaps:**
Gaps larger than `max_gap_to_fill_hours` are reported in `gap_report` but NOT filled with MISSING rows to avoid creating thousands of entries. Only small gaps are filled.

See `?flag_vh_quality` for full details.

## 2b. Zero-Flow Correction (Spacing Adjustment)

### Why Zero-Flow Correction?

Heat pulse velocity sensors can experience **probe spacing errors** due to:
- Slight misalignment during installation
- Tree swelling/shrinking with moisture changes
- Bark expansion after rain events
- Seasonal wood movement

These spacing errors cause **systematic bias** in velocity estimates. During periods of true zero flow (no transpiration), misaligned probes will still report non-zero velocities.

**The Burgess et al. (2001) correction** uses zero-flow calibration to:
1. Calculate the apparent velocity when true flow is zero (the "zero offset")
2. Derive correction coefficients that account for probe misalignment
3. Apply a linear correction to all velocity measurements

### The Changepoint Approach

For datasets spanning days to months, probe alignment often **changes over time** due to tree swelling/shrinking, seasonal wood movement, or environmental conditions. The changepoint-based correction method handles this by:

1. **Detecting baseline shifts** - Identifies when the zero offset changes
2. **Segmenting the time series** - Divides data into periods with consistent probe alignment
3. **Applying segment-specific corrections** - Each segment gets its own zero offset and correction coefficients

This matches the real-world workflow used by researchers analyzing long-term sap flow data.

### Workflow 1: Automatic Changepoint Detection (Both Sensors)

Let the algorithm detect changepoints from the outer sensor and apply correction to both inner and outer sensors:

```{r eval=FALSE}
# Step 1: Calculate daily minimum velocities (from outer sensor)
daily_min <- calculate_daily_minima(
  vh_data = vh_results,
  sensor_position = "outer",
  method = "HRM"
)

# Step 2: Detect changepoints (baseline shifts indicating probe movement)
cpt_result <- detect_changepoints(
  daily_min = daily_min,
  penalty = "MBIC",                  # Options: "MBIC" (conservative), "BIC", "Manual"
  detection_type = "mean",           # Detect mean changes (baseline shifts)
  min_segment_days = 7,              # Minimum segment length
  merge_short_segments = TRUE        # Merge spurious short segments
)

# View detected changepoints
print(cpt_result$changepoints)
print(cpt_result$segments)

# Step 3: Apply correction to BOTH sensors
# Uses same segments, but calculates separate baselines per sensor
correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_results,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  k_assumed = 0.0025
)

vh_corrected <- correction$vh_corrected
```

**Key Points:**
- Changepoints detected from **outer sensor only** (more reliable, less wounding damage)
- Same segments applied to **both inner and outer** sensors
- Each sensor gets its **own baseline** within each segment
- Burgess correction only applied to **HRM** (validated method)

**When to Use Automatic Detection:**
- Long deployments (> 1 month)
- Data spans wet/dry seasonal transitions
- You want an objective, reproducible approach
- Unsure where baseline shifts occurred

**Penalty Selection:**
- **MBIC** (recommended) - Most conservative, fewest changepoints
- **BIC** - Moderate, more changepoints than MBIC
- **Manual** (e.g., `penalty_value = 50`) - Full control over sensitivity

### Workflow 2: Manual Changepoint Specification (Both Sensors)

When you have domain knowledge about probe conditions, specify changepoints manually for both sensors:

```{r eval=FALSE}
# Simple: Auto-detect baselines for both sensors
correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_results,
  changepoints = c("2024-03-15", "2024-06-10"),
  method = "HRM"
)

vh_corrected <- correction$vh_corrected
```

**With Per-Sensor Baseline Overrides:**

If you have different known zero offsets for inner vs outer sensors (e.g., from cut-stem experiments):

```{r eval=FALSE}
correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_results,
  changepoints = c("2024-03-15", "2024-06-10"),
  baseline_overrides_outer = list(
    "seg_1" = 0.8,   # Segment 1: outer sensor manual baseline
    "seg_2" = 1.2    # Segment 2: outer sensor manual baseline
    # Segment 3 auto-detects for outer
  ),
  baseline_overrides_inner = list(
    "seg_1" = 1.1,   # Segment 1: inner sensor manual baseline
    # Segments 2 and 3 auto-detect for inner
  ),
  method = "HRM"
)

vh_corrected <- correction$vh_corrected
```

**Note:** Segment IDs are "seg_1", "seg_2", "seg_3", etc. You can mix manual and auto-detected baselines - only specify the segments you want to override.

**When to Use Manual Specification:**
- You have field notes about probe conditions
- Known disturbance events (rain, repositioning, animal damage)
- Cut-stem calibration data available
- Want to test sensitivity to specific changepoints

### Workflow 3: Junction Smoothing

After applying segment-based corrections, there may be artificial discontinuities at segment boundaries. Smooth these junctions using a moving average:

```{r eval=FALSE}
# Apply junction smoothing (HRM only)
vh_smoothed <- smooth_segment_junctions(
  vh_data = vh_corrected,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  window_size = 3,  # Default: 3 points either side of junction
  verbose = TRUE
)
```

**Important Notes:**
- Junction smoothing is **only applied to HRM** (Burgess correction is HRM-specific)
- Default window size is 3 points (configurable)
- Smoothing prevents artificial jumps at changepoint boundaries
- Apply smoothing AFTER spacing correction but BEFORE method calibration
- Both inner and outer sensors are smoothed independently

### Diagnostic Plots

Visualise changepoints and correction impacts:

```{r eval=FALSE}
# Interactive changepoint visualisation
plot_changepoints_interactive(
  daily_min = cpt_result$daily_min_with_segments,
  changepoints = cpt_result$changepoints,
  segments = extract_segment_baselines(cpt_result),
  show_baseline_values = TRUE
)

# Compare before/after correction
plot_spacing_correction_comparison(
  spacing_result = correction,
  sensor_position = "outer",
  show_difference = TRUE
)

# View Burgess coefficient lookup curves
lookup <- calculate_burgess_coefficients()
plot_burgess_coefficients(
  lookup_table = lookup,
  zero_vh_observed = c(0.8, 1.2),  # Your observed zero offsets
  labels = c("Segment 1", "Segment 2")
)
```

### Understanding Correction Results

```{r eval=FALSE}
# View segment-specific corrections
for (seg in correction$segment_results) {
  cat("\nSegment", seg$segment_id, ":\n")
  cat("  Period:", format(seg$start_datetime), "to", format(seg$end_datetime), "\n")
  cat("  Zero offset:", seg$zero_vh, "cm/hr\n")
  cat("  Baseline source:", seg$baseline_source, "\n")  # "auto-detected" or "user-specified"
  cat("  Correction:", seg$correction_formula, "\n")
  cat("  Severity:", seg$severity, "\n")
}

# Compare uncorrected vs corrected
summary(vh_results$Vh_cm_hr[vh_results$sensor_position == "outer"])
summary(vh_corrected$Vh_cm_hr_sc[vh_corrected$sensor_position == "outer"])
```

**Severity Assessment:**

| Zero Offset | Severity | Interpretation |
|-------------|----------|----------------|
| ≤ 1 cm/hr | None/Minor | Typical field installation |
| 1-3 cm/hr | Minor | Acceptable, correction reliable |
| 3-5 cm/hr | Moderate | Significant misalignment |
| 5-10 cm/hr | Severe | Major misalignment, elevated uncertainty |
| > 10 cm/hr | Critical | **Discard data, reinstall probes** |

### Best Practices

1. **Always correct BEFORE downstream analyses** (flux scaling, tree water use)
2. **Check for baseline shifts** - Plot daily minima to identify potential changepoints
3. **Use multiple segments for long deployments** - Don't assume constant alignment
4. **Validate with field notes** - Compare detected changepoints with field observations
5. **Correct both sensors independently** - They may have different offsets
6. **Document your approach** - Record whether automatic or manual, and why
7. **Create diagnostic plots** - Visually confirm segment quality

### Integration with Quality Control

Spacing correction should be applied **after** quality flagging:

```{r eval=FALSE}
# Recommended workflow order:
# 1. Calculate velocities
vh_results <- calc_heat_pulse_velocity(heat_pulse_data, methods = "HRM")

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Spacing correction (THIS STEP)
daily_min <- calculate_daily_minima(vh_flagged)
cpt_result <- detect_changepoints(daily_min)
correction <- apply_spacing_correction_per_segment(
  vh_data = vh_flagged,
  changepoints = cpt_result$changepoints,
  sensor_position = "outer"
)
vh_corrected <- correction$vh_corrected
```

See `?apply_spacing_correction_per_segment`, `?apply_manual_spacing_correction`, `?detect_changepoints`, and `?calculate_daily_minima` for detailed parameter documentation.

## 2b. Wound Correction

### Why Wound Correction is Needed

When probes are inserted into tree sapwood, they physically damage the tissue, creating "wound" tissue around each probe hole. This wound tissue:

- Has different thermal properties than healthy sapwood
- Creates a thermal barrier affecting heat pulse propagation
- Causes **systematic underestimation** of sap velocity (40-60% or more)
- Effect increases with wound diameter and flow rate

### The Correction Method

Wound correction uses linear coefficients from Burgess et al. (2001) lookup tables:

```
Vc = B × Vh
```

Where:
- `Vc` = Corrected velocity (cm/hr)
- `B` = Correction coefficient (typically 1.7-2.6, depending on wound diameter)
- `Vh` = Input velocity (spacing-corrected)

The correction coefficient `B` depends on:
1. **Wound diameter** - The drill bit size used for probe installation (typically 1.7-3.0 mm)
2. **Probe spacing** - 5mm (standard) or 6mm (legacy)

### Applying Wound Correction

```{r eval=FALSE}
# View available wound coefficients
list_wound_coefficients()

# Apply wound correction (will prompt for confirmation)
vh_wound_corrected <- apply_wound_correction(
  vh_data = vh_corrected,        # After spacing correction
  wound_diameter = 0.20,          # 2.0mm drill bit (in cm)
  probe_spacing = "5mm"           # Standard ICT probe spacing
)

# Check the correction factor applied
unique(vh_wound_corrected$wound_correction_factor)  # e.g., 1.9216
```

### Reading Wound Diameter from Configuration

Wound diameter can be stored in wood properties YAML files:

```{r eval=FALSE}
# If wound_diameter is in wood_properties YAML
vh_wound_corrected <- apply_wound_correction(
  vh_data = vh_corrected,
  wood_properties = "eucalyptus"  # Reads wound_diameter from YAML
)
```

The YAML file includes:
```yaml
probe_installation:
  wound_diameter: 0.20    # cm (2.0mm drill bit)
  probe_spacing: '5mm'    # standard
```

### Wound Correction Coefficients

Common wound diameters and their correction factors (5mm probe spacing):

| Drill Bit | Wound (cm) | B Coefficient | Correction |
|-----------|------------|---------------|------------|
| 1.7 mm | 0.17 | 1.73 | +73% |
| 2.0 mm | 0.20 | 1.92 | +92% |
| 2.5 mm | 0.25 | ~2.25 | +125% |
| 3.0 mm | 0.30 | 2.64 | +164% |

### Workflow Position

Wound correction should be applied **after** spacing correction but **before** method calibration:

```{r eval=FALSE}
# Complete correction workflow:
# 1. Calculate velocities
vh_results <- calc_heat_pulse_velocity(heat_pulse_data)

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Spacing correction
correction <- apply_spacing_correction_both_sensors(vh_flagged, ...)
vh_spacing_corrected <- correction$vh_corrected

# 4. Wound correction (THIS STEP)
vh_wound_corrected <- apply_wound_correction(
  vh_data = vh_spacing_corrected,
  wound_diameter = 0.20
)

# 5. Method calibration (next section)
# ...
```

See `?apply_wound_correction` and `?list_wound_coefficients` for detailed documentation.

## 2c. Method Calibration (Aligning Secondary Methods to HRM)

### Why Method Calibration?

After spacing and wound correction, **HRM** provides the most reliable sap velocity estimates across all flow conditions because it has been validated with Burgess correction. However, other methods (MHR, Tmax, HRMXa, etc.) may provide useful information at higher flow rates.

**Method calibration** aligns secondary methods to the HRM scale using regression in overlapping flow regions. This allows you to:
1. Use HRM at low flows (most accurate)
2. Use calibrated secondary methods at higher flows (better sensitivity)
3. Maintain consistency across the full flow range

**Important:** Calibration should be performed **AFTER** spacing and wound correction, when HRM values are most reliable.

### Workflow 1: Automatic Threshold Optimization (Single Method)

Find the optimal threshold for calibrating one secondary method to HRM:

```{r eval=FALSE}
# Find optimal threshold for MHR calibration
calibration_mhr <- find_optimal_calibration_threshold(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_method = "MHR",
  sensor_position = "outer",
  threshold_start = 0,
  threshold_max = 20,
  threshold_step = 0.5,
  fit_type = "auto",        # "linear", "quadratic", or "auto"
  create_plots = TRUE,
  verbose = TRUE
)

# View optimal result
print(calibration_mhr$optimal_threshold)   # e.g., 2.5 cm/hr
print(calibration_mhr$optimal_r_squared)   # e.g., 0.985
print(calibration_mhr$optimal_fit_type)    # "linear" or "quadratic"
```

**How it works:**
- Tests multiple threshold values (0 to 20 cm/hr by default)
- For each threshold, performs regression using only HRM values above that threshold
- Selects threshold with highest R²
- Returns diagnostic plots showing R² vs threshold

### Workflow 2: Manual Threshold Override

If you disagree with the automatic threshold selection (e.g., you prefer a threshold with slightly lower R² but more data points):

```{r eval=FALSE}
# Use manual threshold instead of automatic optimization
calibration_mhr <- find_optimal_calibration_threshold(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_method = "MHR",
  sensor_position = "outer",
  manual_threshold = 3.0,   # Your chosen threshold
  create_plots = TRUE
)

# Result will use your threshold, skip optimization
```

### Workflow 3: Multi-Method Batch Calibration

Calibrate multiple secondary methods at once:

```{r eval=FALSE}
# Calibrate all secondary methods to HRM
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_methods = c("MHR", "Tmax_Klu", "HRMXa"),
  sensor_position = "outer",
  threshold_start = 0,
  threshold_max = 20,
  threshold_step = 0.5
)

# View results for each method
print(calibrations$MHR$optimal_threshold)
print(calibrations$Tmax_Klu$optimal_threshold)
print(calibrations$HRMXa$optimal_threshold)
```

**With Mixed Manual/Automatic Thresholds:**

```{r eval=FALSE}
# Override specific methods, auto-optimize others
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_corrected,
  primary_method = "HRM",
  secondary_methods = c("MHR", "Tmax_Klu", "HRMXa"),
  sensor_position = "outer",
  manual_thresholds = list(
    MHR = 2.5,          # Manual threshold for MHR
    # Tmax_Klu auto-optimizes
    HRMXa = 1.5         # Manual threshold for HRMXa
  )
)
```

### Workflow 4: Apply Calibration Transformation

Once calibrated, transform your secondary method data to the HRM scale:

```{r eval=FALSE}
# Single method transformation
vh_calibrated_mhr <- transform_secondary_method(
  vh_original = vh_corrected,
  calibration = calibration_mhr$optimal_calibration,
  method = "MHR"
)

# Multi-method transformation (applies all calibrations)
vh_calibrated_all <- transform_multiple_methods(
  vh_original = vh_corrected,
  calibrations = calibrations
)
```

### Workflow 5: Interactive Comparison Plots

Visualize calibration results with interactive date range and method selection:

```{r eval=FALSE}
# Plot calibration comparison (interactive prompts)
plot_calibration_comparison(
  vh_original = vh_corrected,
  vh_calibrated = vh_calibrated_all,
  calibration = calibrations  # Pass multi-method object
)

# You'll be prompted to:
# 1. Select which method to plot (if multiple available)
# 2. Enter start date for time window
# 3. Enter end date for time window

# Or specify directly (non-interactive)
plot_calibration_comparison(
  vh_original = vh_corrected,
  vh_calibrated = vh_calibrated_all,
  calibration = calibrations,
  method = "MHR",                    # Specific method
  start_date = "2024-03-01",
  end_date = "2024-03-31",
  aggregation = "daily"              # "none", "hourly", "daily"
)
```

### Understanding Calibration Results

```{r eval=FALSE}
# Inspect calibration details
cal <- calibration_mhr$optimal_calibration

cat("Fit type:", cal$fit_type, "\n")         # "linear" or "quadratic"
cat("Intercept:", cal$coefficients[1], "\n")
cat("Slope:", cal$coefficients[2], "\n")
if (cal$fit_type == "quadratic") {
  cat("Quadratic term:", cal$coefficients[3], "\n")
}
cat("R²:", cal$r_squared, "\n")
cat("RMSE:", cal$rmse, "cm/hr\n")
cat("Sample size:", cal$n_points, "\n")
```

### Best Practices

1. **Always calibrate AFTER spacing correction** - HRM must be corrected first
2. **Use outer sensor for calibration** - More reliable, less wounding damage
3. **Check R² values** - Aim for R² > 0.90 for reliable calibration
4. **Validate threshold selection** - Review R² vs threshold plots
5. **Consider sample size** - Very high thresholds may have too few points
6. **Test sensitivity** - Try different thresholds to assess robustness
7. **Document your choices** - Record which thresholds and why

### Integration with Complete Workflow

```{r eval=FALSE}
# Complete workflow order:
# 1. Calculate velocities (multiple methods)
vh_results <- calc_heat_pulse_velocity(heat_pulse_data, methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"))

# 2. Quality control
qc_results <- flag_vh_quality(vh_results)
vh_flagged <- qc_results$vh_flagged

# 3. Spacing correction (HRM only, both sensors)
daily_min <- calculate_daily_minima(vh_flagged, sensor_position = "outer", method = "HRM")
cpt_result <- detect_changepoints(daily_min)
correction <- apply_spacing_correction_both_sensors(vh_flagged, cpt_result$changepoints, method = "HRM")
vh_corrected <- correction$vh_corrected

# 4. Junction smoothing (HRM only)
vh_smoothed <- smooth_segment_junctions(vh_corrected, cpt_result$changepoints, method = "HRM")

# 5. Method calibration (THIS STEP - secondary methods to corrected HRM)
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_smoothed,
  primary_method = "HRM",
  secondary_methods = c("MHR", "HRMXa", "Tmax_Klu"),
  sensor_position = "outer"
)

# 6. Apply calibrations
vh_final <- transform_multiple_methods(vh_smoothed, calibrations)

# Now vh_final contains:
# - HRM: spacing-corrected and junction-smoothed (reference method)
# - MHR, HRMXa, Tmax_Klu: calibrated to HRM scale
```

See `?find_optimal_calibration_threshold`, `?calibrate_multiple_methods`, `?transform_secondary_method`, and `?plot_calibration_comparison` for detailed documentation.

## 3. Visualise Results

### Time Series Plot

```{r fig.width=8, fig.height=5}
# Plot velocity time series
plot_vh_timeseries(
  vh_results,
  methods = c("HRM", "MHR", "HRMXa"),
  sensor_position = "outer"
)
```

### Heat Pulse Trace Plot

Visualise individual heat pulse responses and see exactly where each method calculated its result:

```{r fig.width=8, fig.height=6}
# Plot trace for a single pulse
plot_heat_pulse_trace(
  heat_pulse_data,
  vh_results,
  pulse_id = 5,
  show_methods = c("HRM", "HRMXa", "Tmax_Klu")
)
```

The shaded regions and markers show which time points each method used for its calculation:
- **HRM**: Grey shaded window showing averaging period
- **HRMXa**: Blue shaded window showing averaging period
- **HRMXb**: Green shaded window showing averaging period
- **MHR**: Orange shaded window showing time span from upstream to downstream peak, with orange points and lines marking both upstream and downstream peaks
- **Tmax methods**: Dark green vertical line and point marking time to maximum temperature

This is invaluable for:
- Understanding why methods give different results
- Diagnosing problematic pulses
- Validating calculation windows
- Visualizing the temporal dynamics of heat pulse transport

### Method Comparison

```{r fig.width=8, fig.height=6}
# Compare two methods across all pulses
plot_method_comparison(
  vh_results,
  method1 = "HRM",
  method2 = "MHR",
  sensor_position = "outer"
)
```


# Configurations

## Wood Properties

Wood properties affect thermal calculations. Use built-in configurations or create custom ones:

```{r eval=FALSE}
# Use built-in configurations
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus"  # or "pine", "generic_sw"
)

# Override specific properties
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "eucalyptus",
  wood_overrides = list(
    thermal_diffusivity = 0.0028,  # cm²/s
    dbh = 45.2,                    # cm
    sapwood_depth = 3.5            # cm
  )
)
```

### Create Custom Wood Properties

Create a YAML file with your species-specific properties:

```yaml
# wood_my_species.yaml
species:
  common_name: "My Species"
  scientific_name: "Genus species"

thermal_properties:
  thermal_diffusivity:
    value: 0.0025
    units: "cm²/s"
    source: "Measured from cores"

  thermal_conductivity:
    value: 0.0050
    units: "W/(m·K)"

  volumetric_heat_capacity:
    value: 2.0
    units: "MJ/(m³·K)"

physical_properties:
  wood_density:
    value: 550
    units: "kg/m³"

  moisture_content:
    value: 0.40
    units: "fraction"

tree_measurements:
  dbh:
    value: 35.0
    units: "cm"

  sapwood_depth:
    value: 2.8
    units: "cm"
```

Load your custom configuration:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  wood_properties = "path/to/wood_my_species.yaml"
)
```

## Probe Configuration

Probe configurations define hardware specifications:

```{r eval=FALSE}
# Use default symmetric probe (ICT SFM1x standard)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "symmetrical"  # Default
)

# Use asymmetric probe (CHPM optimised)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  probe_config = "asymmetrical"
)
```

### Create Custom Probe Configuration

For custom probe geometries:

```yaml
# probe_custom.yaml
probe_type: "custom_probe"
description: "Custom probe geometry"

geometry:
  probe_spacing:
    value: 0.6
    units: "cm"

  probe_diameter:
    value: 1.5
    units: "mm"

  thermistor_positions:
    downstream_outer: 0.6   # cm from heater
    downstream_inner: 0.3
    upstream_outer: -0.6
    upstream_inner: -0.3

measurement:
  heat_pulse_duration:
    value: 2.0
    units: "seconds"
```

# Advanced Topics

## Custom Calculation Parameters

Override default calculation windows:

```{r eval=FALSE}
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = "HRM",
  parameters = list(
    pre_pulse = 30,      # Baseline period (sec)
    HRM_start = 70,      # HRM window start (sec)
    HRM_end = 110,       # HRM window end (sec)
    L = 0.5,             # HRMX lower bound (proportion of max temp)
    H = 0.8              # HRMX upper bound
  )
)
```

## Filter by Quality

The two-tier quality flag system (CALC_ and DATA_ prefixes) helps identify different types of issues:

```{r}
# Keep only high-quality results (no calculation or data issues)
good_results <- vh_results[vh_results$quality_flag == "OK", ]

# View all quality flags
table(vh_results$quality_flag, vh_results$method)

# Filter out calculation failures but keep data quality issues for manual review
calc_ok <- vh_results[!grepl("^CALC_", vh_results$quality_flag), ]

# After running flag_vh_quality(), you can filter by both tiers
# qc_results <- flag_vh_quality(vh_results)
# clean_data <- qc_results$vh_flagged[qc_results$vh_flagged$quality_flag == "OK", ]
```

## Export Results

```{r eval=FALSE}
# Export to CSV
write.csv(vh_results, "sap_velocity_results.csv", row.names = FALSE)

# Export with metadata
saveRDS(list(
  results = vh_results,
  metadata = heat_pulse_data$metadata,
  processing_date = Sys.time()
), "sap_velocity_complete.rds")
```

# Workflow Summary

```r
# Complete workflow with all processing steps
library(sapfluxr)

# PHASE 1: Import and Initial Calculations
# ========================================

# 1. Import
heat_pulse_data <- read_heat_pulse_data("mydata.txt")

# 1a. (Optional) Fix clock drift if detected
# heat_pulse_data <- fix_clock_drift(
#   data = heat_pulse_data,
#   observed_device_time = as.POSIXct("2025-01-16 08:05:00"),
#   observed_actual_time = as.POSIXct("2025-01-16 08:00:00")
# )

# 2. Calculate velocities (all methods)
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu"),
  wood_properties = "eucalyptus"
)

# 2a. Apply quality control
qc_results <- flag_vh_quality(
  vh_results,
  wood_properties = "eucalyptus",
  detect_missing_pulses = TRUE,
  detect_outliers = TRUE
)
vh_flagged <- qc_results$vh_flagged

# PHASE 2-3: Changepoint Detection and Spacing Correction
# ========================================================

# 2b. Detect changepoints (from outer sensor HRM)
daily_min <- calculate_daily_minima(
  vh_data = vh_flagged,
  sensor_position = "outer",
  method = "HRM"
)

cpt_result <- detect_changepoints(
  daily_min = daily_min,
  penalty = "MBIC",
  min_segment_days = 7
)

# Apply spacing correction to both sensors
correction <- apply_spacing_correction_both_sensors(
  vh_data = vh_flagged,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  k_assumed = 0.0025
)

vh_corrected <- correction$vh_corrected

# Apply junction smoothing (HRM only)
vh_smoothed <- smooth_segment_junctions(
  vh_data = vh_corrected,
  changepoints = cpt_result$changepoints,
  method = "HRM",
  window_size = 3
)

# PHASE 5: Method Calibration
# ============================

# Calibrate secondary methods to corrected HRM
calibrations <- calibrate_multiple_methods(
  vh_corrected = vh_smoothed,
  primary_method = "HRM",
  secondary_methods = c("MHR", "HRMXa", "Tmax_Klu"),
  sensor_position = "outer"
)

# Apply calibrations
vh_final <- transform_multiple_methods(
  vh_original = vh_smoothed,
  calibrations = calibrations
)

# PHASE 6: Visualisation and Export
# ==================================

# 3. Visualise results
plot_vh_timeseries(vh_final, methods = c("HRM", "MHR", "HRMXa"))
plot_calibration_comparison(vh_smoothed, vh_final, calibrations)

# 4. Export final processed data
write.csv(vh_final, "sap_velocity_final.csv", row.names = FALSE)

# Export with full metadata
saveRDS(list(
  data = vh_final,
  changepoints = cpt_result,
  correction = correction,
  calibrations = calibrations,
  processing_date = Sys.time()
), "sap_velocity_complete.rds")
```

## Common Workflows

### Standard Analysis
```r
# Use proven methods for routine analysis
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR")
)
```

### Method Comparison
```r
# Compare multiple methods to find the best for your data
vh_results <- calc_heat_pulse_velocity(
  heat_pulse_data,
  methods = c("HRM", "MHR", "HRMXa", "Tmax_Klu")
)
```


# Getting Help

- **Package documentation**: `?calc_heat_pulse_velocity`
- **Report issues**: https://github.com/neez777/sapfluxr/issues
- **Method details**: See `knowledge_docs/` in package installation

# References

- Burgess, S. S. O., Adams, M. A., Turner, N. C., Beverly, C. R., Ong, C. K., Khan, A. A. H., & Bleby, T. M. (2001). An improved heat pulse method to measure low and reverse rates of sap flow in woody plants. *Tree Physiology*, 21(9), 589-598.

- Cohen, Y., Fuchs, M., & Green, G. C. (1981). Improvement of the heat pulse method for determining sap flow in trees. *Plant, Cell & Environment*, 4(5), 391-397.

- Forster, M. A. (2020). How significant is nocturnal sap flow? *Tree Physiology*, 40(8), 1179-1190.

- Kluitenberg, G. J., & Ham, J. M. (2004). Improved theory for calculating sap flow with the heat pulse method. *Agricultural and Forest Meteorology*, 126(1-2), 169-173.

- Lopez, J. G., Morán-López, T., Benito Garzón, M., & Oliveras Menor, I. (2021). An improved heat pulse method using a single probe for determining sap flow in temperate trees. *Tree Physiology*, 41(12), 2437-2449.
